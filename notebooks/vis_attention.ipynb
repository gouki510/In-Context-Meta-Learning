{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class SamplingDataset(object):\n",
    "  def __init__(self,conf):\n",
    "    self.num_classes = conf.num_classes\n",
    "    self.dim = conf.dim\n",
    "    self.num_labels = conf.num_labels\n",
    "    self.mu, self.labels = self._get_data()\n",
    "\n",
    "  def _get_data(self):\n",
    "    mu = torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(self.num_classes,self.dim))\n",
    "    labels = torch.randint(self.num_labels, size=(self.num_classes,1))\n",
    "    return mu, labels\n",
    "\n",
    "class SamplingLoader(DataLoader):\n",
    "\n",
    "  def __init__(self,conf, dataset):\n",
    "    self.dataset = dataset\n",
    "    self.mu, self.labels = self.dataset.mu, self.dataset.labels\n",
    "    self.data_type = conf.data_type\n",
    "    self.num_seq = conf.num_seq\n",
    "    self.alpha = conf.alpha\n",
    "    self.num_classes = conf.num_classes\n",
    "    self.num_labels = conf.num_labels\n",
    "    self.ways = conf.ways\n",
    "    self.p_bursty = conf.p_bursty\n",
    "    self.p_icl = conf.p_icl\n",
    "    self.eps = conf.eps\n",
    "    self.dim = conf.dim\n",
    "    if self.ways != 0:\n",
    "      assert self.num_seq % self.ways == 0\n",
    "    if self.ways == 0:\n",
    "      self.p_bursty = 0\n",
    "    prob = np.array([1/((k+1)**self.alpha) for k in range(self.num_classes)])\n",
    "    self.prob = prob/prob.sum()\n",
    "\n",
    "  def get_seq(self):\n",
    "    while True:\n",
    "      if self.data_type==\"bursty\":\n",
    "        if self.p_icl > np.random.rand():\n",
    "            # choise few shot example\n",
    "            num_few_shot_class = self.num_seq//self.ways\n",
    "            mus, labels = self._get_novel_class_seq(num_few_shot_class)\n",
    "            # mus = self.mu[few_shot_class]\n",
    "            mus = np.repeat(mus, self.ways, axis=0) # expand ways\n",
    "            # labels = self.labels[few_shot_class]\n",
    "            labels = np.repeat(labels, self.ways, axis=0) # expand ways\n",
    "            classes = np.arange(num_few_shot_class)\n",
    "            classes = np.repeat(classes, self.ways)\n",
    "            # add noise\n",
    "            x = self.add_noise(mus)\n",
    "            # permutation shuffle\n",
    "            ordering = np.random.permutation(self.num_seq)\n",
    "            mus = mus[ordering]\n",
    "            x = x[ordering]\n",
    "            labels = labels[ordering]\n",
    "            classes = classes[ordering]\n",
    "            # select query labels\n",
    "            query_class_idx = np.random.choice(len(classes), 1)\n",
    "            query_class = classes[query_class_idx]\n",
    "            query_label = labels[query_class_idx]\n",
    "            query_mu = mus[query_class_idx]\n",
    "            query_x = self.add_noise(query_mu)\n",
    "            # concat\n",
    "            x = torch.cat([x, query_x])\n",
    "            labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "            \n",
    "            yield {\n",
    "                \"examples\":x.to(torch.float32),\n",
    "                \"labels\":labels,\n",
    "                \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "          if self.p_bursty > np.random.rand():\n",
    "            # choise few shot example\n",
    "            num_few_shot_class = self.num_seq//self.ways\n",
    "            few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "            mus = self.mu[few_shot_class]\n",
    "            mus = np.repeat(mus, self.ways, axis=0) # expand ways\n",
    "            labels = self.labels[few_shot_class]\n",
    "            labels = np.repeat(labels, self.ways, axis=0) # expand ways\n",
    "            classes = np.repeat(few_shot_class, self.ways)\n",
    "            # add noise\n",
    "            x = self.add_noise(mus)\n",
    "            # permutation shuffle\n",
    "            ordering = np.random.permutation(self.num_seq)\n",
    "            x = x[ordering]\n",
    "            labels = labels[ordering]\n",
    "            classes = classes[ordering]\n",
    "            # select query labels\n",
    "            query_class = np.random.choice(few_shot_class, 1)\n",
    "            query_label = self.labels[query_class]\n",
    "            query_mu = self.mu[query_class]\n",
    "            query_x = self.add_noise(query_mu)\n",
    "            # concat\n",
    "            x = torch.cat([x, query_x])\n",
    "            labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "            yield {\n",
    "                \"examples\":x.to(torch.float32),\n",
    "                \"labels\":labels,\n",
    "                \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "            }\n",
    "            \n",
    "          else:\n",
    "            # rank frequency\n",
    "            classes = np.random.choice(self.num_classes, self.num_seq+1, p=self.prob)\n",
    "            mus = self.mu[classes]\n",
    "            labels = self.labels[classes]\n",
    "            x = self.add_noise(mus)\n",
    "            # permutation shuffle\n",
    "            ordering = np.random.permutation(self.num_seq+1)\n",
    "            x = x[ordering]\n",
    "            labels = labels[ordering]\n",
    "            classes = classes[ordering]\n",
    "\n",
    "            yield {\n",
    "                \"examples\":x.to(torch.float32),\n",
    "                \"labels\":labels.flatten(),\n",
    "                \"classes\" : torch.from_numpy(classes)\n",
    "            }\n",
    "\n",
    "      elif self.data_type == \"no_support\":\n",
    "          # rank frequency\n",
    "          classes = np.random.choice(self.num_classes, self.num_seq+1, p=self.prob)\n",
    "          mus = self.mu[classes]\n",
    "          labels = self.labels[classes]\n",
    "          x = self.add_noise(mus)\n",
    "          # permutation shuffle\n",
    "          ordering = np.random.permutation(self.num_seq+1)\n",
    "          x = x[ordering]\n",
    "          labels = labels[ordering]\n",
    "          classes = classes[ordering]\n",
    "\n",
    "          yield {\n",
    "              \"examples\":x.to(torch.float32),\n",
    "              \"labels\":labels.flatten(),\n",
    "              \"classes\" : torch.from_numpy(classes)\n",
    "          }\n",
    "          \n",
    "      elif self.data_type == \"holdout\":\n",
    "        # choise few shot example\n",
    "        num_few_shot_class = self.num_seq//self.ways\n",
    "        mus, labels = self._get_novel_class_seq(num_few_shot_class)\n",
    "        # mus = self.mu[few_shot_class]\n",
    "        mus = np.repeat(mus, self.ways, axis=0) # expand ways\n",
    "        # labels = self.labels[few_shot_class]\n",
    "        labels = np.repeat(labels, self.ways, axis=0) # expand ways\n",
    "        classes = np.arange(num_few_shot_class)\n",
    "        classes = np.repeat(classes, self.ways)\n",
    "        # add noise\n",
    "        x = self.add_noise(mus)\n",
    "        # permutation shuffle\n",
    "        ordering = np.random.permutation(self.num_seq)\n",
    "        mus = mus[ordering]\n",
    "        x = x[ordering]\n",
    "        labels = labels[ordering]\n",
    "        classes = classes[ordering]\n",
    "        # select query labels\n",
    "        query_class_idx = np.random.choice(len(classes), 1)\n",
    "        query_class = classes[query_class_idx]\n",
    "        query_label = labels[query_class_idx]\n",
    "        query_mu = mus[query_class_idx]\n",
    "        query_x = self.add_noise(query_mu)\n",
    "        # concat\n",
    "        x = torch.cat([x, query_x])\n",
    "        labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "        \n",
    "        yield {\n",
    "            \"examples\":x.to(torch.float32),\n",
    "            \"labels\":labels,\n",
    "            \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "        }\n",
    "\n",
    "      elif self.data_type == \"flip\":\n",
    "        # choise few shot example\n",
    "        num_few_shot_class = self.num_seq//self.ways\n",
    "        few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "        mus = self.mu[few_shot_class]\n",
    "        mus = np.repeat(mus, self.ways, axis=0) # expand ways\n",
    "        classes = np.repeat(few_shot_class, self.ways)\n",
    "        # label flip\n",
    "        labels = (self.labels[classes] + 1) % self.num_labels\n",
    "        # add noise\n",
    "        x = self.add_noise(mus)\n",
    "        # permutation shuffle\n",
    "        ordering = np.random.permutation(self.num_seq)\n",
    "        x = x[ordering]\n",
    "        labels = labels[ordering]\n",
    "        classes = classes[ordering]\n",
    "        # select query labels\n",
    "        query_class = np.random.choice(few_shot_class, 1)\n",
    "        query_label = (self.labels[query_class] + 1) % self.num_labels\n",
    "        query_mu = self.mu[query_class]\n",
    "        query_x = self.add_noise(query_mu)\n",
    "        # concat\n",
    "        x = torch.cat([x, query_x])\n",
    "        labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "        \n",
    "        yield {\n",
    "            \"examples\":x.to(torch.float32),\n",
    "            \"labels\":labels,\n",
    "            \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "        }\n",
    "    \n",
    "  \n",
    "\n",
    "  def add_noise(self, x):\n",
    "    x = (x+self.eps*torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(x.shape)))/(np.sqrt(1+self.eps**2))\n",
    "    # x = (x+self.eps*np.random.normal(mean=0, std=np.sqrt(1/self.dim), size=(x.shape[0],1)))/(np.sqrt(1+self.eps**2))\n",
    "    return x\n",
    "  \n",
    "  def _get_novel_class_seq(self,num_class):\n",
    "    mu = torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(num_class,self.dim))\n",
    "    labels = torch.randint(self.num_labels, size=(num_class,1))\n",
    "    return mu, labels\n",
    "\n",
    "class IterDataset(IterableDataset):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.generator()\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "class MultiTaskSamplingLoader(DataLoader):\n",
    "\n",
    "  def __init__(self,conf, dataset):\n",
    "    self.dataset = dataset\n",
    "    self.mu, self.labels = self.dataset.mu, self.dataset.labels\n",
    "    self.data_type = conf.data_type\n",
    "    self.num_seq = conf.num_seq\n",
    "    self.alpha = conf.alpha\n",
    "    self.num_classes = conf.num_classes\n",
    "    self.num_task = conf.num_tasks\n",
    "    self.num_labels = conf.num_labels\n",
    "    self.task_ways = conf.task_ways\n",
    "    self.item_ways = conf.item_ways\n",
    "    self.p_bursty = conf.p_bursty\n",
    "    self.p_icl = conf.p_icl\n",
    "    self.eps = conf.eps\n",
    "    self.dim = conf.dim\n",
    "    if self.item_ways != 0 or self.task_ways != 0:\n",
    "      assert self.num_seq % self.item_ways == 0 and self.num_seq % self.task_ways == 0\n",
    "    if self.item_ways == 0 or self.task_ways == 0:\n",
    "      self.p_bursty = 0\n",
    "    prob = np.array([1/((k+1)**self.alpha) for k in range(self.num_classes)])\n",
    "    self.prob = prob/prob.sum()\n",
    "\n",
    "  def get_seq(self):\n",
    "    while True:\n",
    "      if self.data_type==\"bursty\":\n",
    "        if self.p_bursty > np.random.rand():\n",
    "          # choise few shot tasks\n",
    "          num_few_shot_task = self.num_seq//self.task_ways\n",
    "          few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "          tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "          # print(tasks.shape)\n",
    "          \n",
    "          # choise few shot items\n",
    "          num_few_shot_class = self.num_seq//self.item_ways\n",
    "          few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "          mus = self.mu[few_shot_class]\n",
    "          mus = np.repeat(mus, self.item_ways, axis=0) # expand ways\n",
    "          \n",
    "          # choice few shot labels\n",
    "          labels = self.labels[few_shot_class]\n",
    "          labels = np.repeat(labels, self.item_ways, axis=0) # expand ways\n",
    "        \n",
    "          \n",
    "          # classes \n",
    "          classes = np.repeat(few_shot_class, self.item_ways)\n",
    "          # add noise\n",
    "          x = self.add_noise(mus)\n",
    "          # permutation shuffle\n",
    "          ordering = np.random.permutation(self.num_seq)\n",
    "          x = x[ordering]\n",
    "          labels = labels[ordering]\n",
    "          classes = classes[ordering]\n",
    "          task_ordering = np.random.permutation(self.num_seq)\n",
    "          tasks = tasks[task_ordering]\n",
    "          \n",
    "          labels = (labels + tasks) % self.num_labels\n",
    "          \n",
    "          # select query labels\n",
    "          query_class = np.random.choice(few_shot_class, 1)\n",
    "          query_task = np.random.choice(few_shot_task, 1)\n",
    "          query_label = (self.labels[query_class] + query_task) % self.num_labels\n",
    "          query_mu = self.mu[query_class]\n",
    "          query_x = self.add_noise(query_mu)\n",
    "          # concat\n",
    "          x = torch.cat([x, query_x])\n",
    "          labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "          tasks = torch.cat([torch.tensor(tasks).flatten(), torch.tensor(query_task).flatten()])\n",
    "          \n",
    "          yield {\n",
    "              \"tasks\":tasks,\n",
    "              \"examples\":x.to(torch.float32),\n",
    "              \"labels\":labels,\n",
    "              \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "          }\n",
    "          \n",
    "        else:\n",
    "          # rank frequency\n",
    "          num_few_shot_task = self.num_seq//self.task_ways\n",
    "          few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "          tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "          \n",
    "          classes = np.random.choice(self.num_classes, self.num_seq+1, p=self.prob)\n",
    "          mus = self.mu[classes]\n",
    "          labels = self.labels[classes]\n",
    "          x = self.add_noise(mus)\n",
    "          # permutation shuffle\n",
    "          ordering = np.random.permutation(self.num_seq+1)\n",
    "          x = x[ordering]\n",
    "          labels = labels[ordering]\n",
    "          labels = (labels + tasks) % self.num_labels\n",
    "          classes = classes[ordering]\n",
    "          tasks = tasks[ordering]\n",
    "          \n",
    "\n",
    "          yield {\n",
    "              \"tasks\":tasks,\n",
    "              \"examples\":x.to(torch.float32),\n",
    "              \"labels\":labels.flatten(),\n",
    "              \"classes\" : torch.from_numpy(classes)\n",
    "          }\n",
    "\n",
    "      elif self.data_type == \"no_support\":\n",
    "          num_few_shot_task = self.num_seq//self.task_ways\n",
    "          few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "          tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "        \n",
    "          # rank frequency\n",
    "          classes = np.random.choice(self.num_classes, self.num_seq, p=self.prob)\n",
    "          mus = self.mu[classes]\n",
    "          # random label\n",
    "          labels = np.random.randint(self.num_labels, size=(self.num_seq,1))\n",
    "          x = self.add_noise(mus)\n",
    "          # permutation shuffle\n",
    "          ordering = np.random.permutation(self.num_seq)\n",
    "          x = x[ordering]\n",
    "          labels = labels[ordering]\n",
    "          classes = classes[ordering]\n",
    "          tasks = tasks[ordering]\n",
    "          \n",
    "          # select query labels\n",
    "          query_class = np.random.choice(self.num_classes, 1)\n",
    "          query_task = np.random.choice(few_shot_task, 1)\n",
    "          query_label = self.labels[query_class]\n",
    "          query_label = (query_label + query_task) % self.num_labels\n",
    "          query_mu = self.mu[query_class]\n",
    "          query_mu = self.add_noise(query_mu)\n",
    "          \n",
    "          # concat\n",
    "          x = torch.cat([x, query_mu])\n",
    "          labels = torch.cat([torch.from_numpy(labels).flatten(), query_label.flatten()])\n",
    "          tasks = torch.cat([torch.tensor(tasks).flatten(), torch.tensor(query_task).flatten()])\n",
    "          classes = np.concatenate([classes, query_class])\n",
    "\n",
    "          yield {\n",
    "              \"tasks\": tasks,\n",
    "              \"examples\":x.to(torch.float32),\n",
    "              \"labels\":labels.flatten(),\n",
    "              \"classes\" : torch.from_numpy(classes)\n",
    "          }\n",
    "          \n",
    "      elif self.data_type == \"holdout\":\n",
    "        # choise few shot tasks\n",
    "        num_few_shot_task = self.num_seq//self.task_ways\n",
    "        few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "        tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "        false_tasks = np.random.choice(self.num_task, 1, replace=False)\n",
    "        # print(tasks.shape)\n",
    "        \n",
    "        # choise few shot items\n",
    "        num_few_shot_class = self.num_seq//self.item_ways\n",
    "        few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "        mus = self.mu[few_shot_class]\n",
    "        mus = np.repeat(mus, self.item_ways, axis=0) # expand ways\n",
    "        \n",
    "        # choice few shot labels\n",
    "        labels = self.labels[few_shot_class]\n",
    "        labels = np.repeat(labels, self.item_ways, axis=0) # expand ways\n",
    "        \n",
    "        classes = np.repeat(few_shot_class, self.item_ways)\n",
    "        \n",
    "        # add noise\n",
    "        x = self.add_noise(mus)\n",
    "        # permutation shuffle\n",
    "        ordering = np.random.permutation(self.num_seq)\n",
    "        mus = mus[ordering]\n",
    "        x = x[ordering]\n",
    "        labels = labels[ordering]\n",
    "        classes = classes[ordering]\n",
    "        tasks = tasks[ordering]\n",
    "        \n",
    "        labels = (labels + tasks) % self.num_labels\n",
    "        \n",
    "        # select query labels\n",
    "        query_class = np.random.choice(few_shot_class, 1)\n",
    "        query_task = np.random.choice(few_shot_task, 1)\n",
    "        query_label = (self.labels[query_class] + query_task) % self.num_labels\n",
    "        query_mu = self.mu[query_class]\n",
    "        query_x = self.add_noise(query_mu)\n",
    "        # concat\n",
    "        x = torch.cat([x, query_x])\n",
    "        labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "        tasks = torch.cat([torch.tensor(tasks).flatten(), torch.tensor(false_tasks).flatten()])\n",
    "          \n",
    "        \n",
    "        \n",
    "        yield {\n",
    "            \"tasks\":tasks,\n",
    "            \"examples\":x.to(torch.float32),\n",
    "            \"labels\":labels,\n",
    "            \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "        }\n",
    "\n",
    "      elif self.data_type == \"flip\":\n",
    "        # choise few shot example\n",
    "        num_few_shot_class = self.num_seq//self.item_ways\n",
    "        few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "        mus = self.mu[few_shot_class]\n",
    "        mus = np.repeat(mus, self.item_ways, axis=0) # expand ways\n",
    "        classes = np.repeat(few_shot_class, self.item_ways)\n",
    "        # label flip\n",
    "        labels = (self.labels[classes] + 1) % self.num_labels\n",
    "        # add noise\n",
    "        x = self.add_noise(mus)\n",
    "        # permutation shuffle\n",
    "        ordering = np.random.permutation(self.num_seq)\n",
    "        x = x[ordering]\n",
    "        labels = labels[ordering]\n",
    "        classes = classes[ordering]\n",
    "        # select query labels\n",
    "        query_class = np.random.choice(few_shot_class, 1)\n",
    "        query_label = (self.labels[query_class] + 1) % self.num_labels\n",
    "        query_mu = self.mu[query_class]\n",
    "        query_x = self.add_noise(query_mu)\n",
    "        # concat\n",
    "        x = torch.cat([x, query_x])\n",
    "        labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "        \n",
    "        yield {\n",
    "            \"examples\":x.to(torch.float32),\n",
    "            \"labels\":labels,\n",
    "            \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "        }\n",
    "    \n",
    "  \n",
    "\n",
    "  def add_noise(self, x):\n",
    "    x = (x+self.eps*torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(x.shape)))/(np.sqrt(1+self.eps**2))\n",
    "    # x = (x+self.eps*np.random.normal(mean=0, std=np.sqrt(1/self.dim), size=(x.shape[0],1)))/(np.sqrt(1+self.eps**2))\n",
    "    return x\n",
    "  \n",
    "  def _get_novel_class_seq(self,num_class):\n",
    "    mu = torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(num_class,self.dim))\n",
    "    labels = torch.randint(self.num_labels, size=(num_class,1))\n",
    "    return mu, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class TransformerConfig:\n",
    "  num_seq: int = 8\n",
    "  num_layers: int = 2\n",
    "  num_atten_layer: int = 2\n",
    "  d_vocab: int = 32\n",
    "  d_model: int = 128\n",
    "  d_mlp: int = 128\n",
    "  d_head: int = 128\n",
    "  num_heads: int = 1\n",
    "  n_ctx: int = int(((num_seq+1)*2 -1))\n",
    "  act_type: str = \"ReLU\"\n",
    "  use_cache: bool = False\n",
    "  use_ln: bool = True\n",
    "  p_dim: int = 65\n",
    "  d_emb: int = 128\n",
    "  num_classes:int = 512\n",
    "  num_tasks: int = 3\n",
    "  task_ways: int = num_seq\n",
    "  seq_model: str = \"Attention\"  \n",
    "  use_scaled_attention: bool = False\n",
    "  \n",
    "\n",
    "@dataclass\n",
    "class TrainDataConfig:\n",
    "  num_classes: int = 512\n",
    "  dim: int = 63\n",
    "  num_labels: int = 32\n",
    "  eps: float = 0.1\n",
    "  alpha: float = 0\n",
    "  item_ways: int = 2\n",
    "  p_bursty: float = 1\n",
    "  data_type: str = \"bursty\" # bursty, holdout, no_support, flip\n",
    "  num_seq: int = 8\n",
    "  num_holdout_classes: int = 10\n",
    "  num_tasks: int = 3\n",
    "  task_ways: int = 8\n",
    "  p_icl: float = 0\n",
    "  \n",
    "@dataclass\n",
    "class IWLDataConfig(TrainDataConfig):\n",
    "  data_type: str = \"no_support\" # bursty, holdout, no_support, flip\n",
    "\n",
    "@dataclass\n",
    "class ICLDataConfig(TrainDataConfig):\n",
    "  data_type: str = \"holdout\" # bursty, holdout, no_support, flip\n",
    "  # task_ways: int = 8\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ICL2DataConfig(TrainDataConfig):\n",
    "  data_type: str = \"flip\" # bursty, holdout, no_support, flip\n",
    "  \n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "  batch_size: int = 1\n",
    "  optimize_step: int = int(2e5)\n",
    "  lr: float = 0.01\n",
    "  optimizer: str = \"sgd\" # adam, sgd, adamw\n",
    "  every_eval: int = 3000\n",
    "\n",
    "@dataclass\n",
    "class MainConfig:\n",
    "  traindataconfig : TrainDataConfig = TrainDataConfig()\n",
    "  icldataconfig: ICLDataConfig = ICLDataConfig()\n",
    "  iwldataconfig: IWLDataConfig = IWLDataConfig()\n",
    "  icl2dataconfig: ICL2DataConfig = ICL2DataConfig()\n",
    "  modelconfig: TransformerConfig = TransformerConfig()\n",
    "  trainconfig: TrainConfig = TrainConfig()\n",
    "  device: str = \"cuda:1\"\n",
    "  exp_name: str = \"some_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import einops\n",
    "from mamba_ssm import Mamba\n",
    "from einops import rearrange, repeat, einsum\n",
    "\n",
    "\n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(d_vocab, d_model) / np.sqrt(d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.einsum(\"pe,bse->bsp\", self.W, x)\n",
    "\n",
    "\n",
    "class HookPoint(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fwd_hooks = []\n",
    "        self.bwd_hooks = []\n",
    "\n",
    "    def give_name(self, name):\n",
    "        # Called by the model at initialisation\n",
    "        self.name = name\n",
    "\n",
    "    def add_hook(self, hook, dir=\"fwd\"):\n",
    "        # Hook format is fn(activation, hook_name)\n",
    "        # Change it into PyTorch hook format (this includes input and output,\n",
    "        # which are the same for a HookPoint)\n",
    "        def full_hook(module, module_input, module_output):\n",
    "            return hook(module_output, name=self.name)\n",
    "\n",
    "        if dir == \"fwd\":\n",
    "            handle = self.register_forward_hook(full_hook)\n",
    "            self.fwd_hooks.append(handle)\n",
    "        elif dir == \"bwd\":\n",
    "            handle = self.register_backward_hook(full_hook)\n",
    "            self.bwd_hooks.append(handle)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "\n",
    "    def remove_hooks(self, dir=\"fwd\"):\n",
    "        if (dir == \"fwd\") or (dir == \"both\"):\n",
    "            for hook in self.fwd_hooks:\n",
    "                hook.remove()\n",
    "            self.fwd_hooks = []\n",
    "        if (dir == \"bwd\") or (dir == \"both\"):\n",
    "            for hook in self.bwd_hooks:\n",
    "                hook.remove()\n",
    "            self.bwd_hooks = []\n",
    "        if dir not in [\"fwd\", \"bwd\", \"both\"]:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, max_ctx, d_model, weight_scale=1):\n",
    "        super().__init__()\n",
    "        self.W_pos = nn.Parameter(torch.randn(max_ctx, d_model) * weight_scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.W_pos[: x.shape[-2]]\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, epsilon=1e-4, model=[None]):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.w_ln = nn.Parameter(torch.ones(d_model))\n",
    "        self.b_ln = nn.Parameter(torch.zeros(d_model))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.model[0].use_ln:\n",
    "            x = x - x.mean(axis=-1)[..., None]\n",
    "            x = x / (x.std(axis=-1)[..., None] + self.epsilon)\n",
    "            x = x * self.w_ln\n",
    "            x = x + self.b_ln\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "# Attention\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    b : batch size\n",
    "    d : embedding size of token\n",
    "    p : vocabraly size \n",
    "    i : number of heads\n",
    "    h : embedding size of each heads\n",
    "    n_ctx : token size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, d_head, n_ctx, scaled=False):\n",
    "        super().__init__()\n",
    "        self.W_K = nn.Parameter(\n",
    "            torch.randn(num_heads, d_head, d_model) / np.sqrt(d_model)\n",
    "        )\n",
    "        self.W_Q = nn.Parameter(\n",
    "            torch.randn(num_heads, d_head, d_model) / np.sqrt(d_model)\n",
    "        )\n",
    "        self.W_V = nn.Parameter(\n",
    "            torch.randn(num_heads, d_head, d_model) / np.sqrt(d_model)\n",
    "        )\n",
    "        # self.W_O = nn.Parameter(\n",
    "        #     torch.randn(d_model, d_head * num_heads) / np.sqrt(d_model)\n",
    "        # )\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones((n_ctx, n_ctx))))\n",
    "        self.register_buffer(\"atten_matrix\", torch.zeros((num_heads, n_ctx, n_ctx)))\n",
    "        self.d_head = d_head\n",
    "        self.scaled = scaled\n",
    "\n",
    "    def forward(self, x):\n",
    "        k = torch.einsum(\"ihd,bpd->biph\", self.W_K, x)\n",
    "        q = torch.einsum(\"ihd,bpd->biph\", self.W_Q, x)\n",
    "        v = torch.einsum(\"ihd,bpd->biph\", self.W_V, x)\n",
    "        attn_scores_pre = torch.einsum(\"biph,biqh->biqp\", k, q)\n",
    "        attn_scores_masked = torch.tril(attn_scores_pre) - 1e10 * (\n",
    "            1 - self.mask[: x.shape[-2], : x.shape[-2]]\n",
    "        )\n",
    "        if self.scaled:\n",
    "            attn_matrix = F.softmax(attn_scores_masked / np.sqrt(self.d_head), dim=-1)\n",
    "        else:\n",
    "            attn_matrix = F.softmax(attn_scores_masked, dim=-1)\n",
    "        self.set_attention_matrix(attn_matrix.detach().cpu())\n",
    "        z = torch.einsum(\"biph,biqp->biqh\", v, attn_matrix)\n",
    "        z_flat = einops.rearrange(z, \"b i q h -> b q (i h)\")\n",
    "        # out = torch.einsum(\"df,bqf->bqd\", self.W_O, z_flat)\n",
    "        out = z_flat\n",
    "        return out\n",
    "\n",
    "    def set_attention_matrix(self, attn_matrix):\n",
    "        for i in range(self.atten_matrix.shape[0]):\n",
    "            self.atten_matrix[i] = attn_matrix.mean(dim=0)[i]\n",
    "    \n",
    "    def get_attention_matrix(self):\n",
    "        return self.atten_matrix\n",
    "    \n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, d_in, d_out, act_type, weight_scale=1):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(d_out, d_in))\n",
    "        torch.nn.init.normal_(self.W, mean=0, std=weight_scale / np.sqrt(d_in))\n",
    "        self.b = nn.Parameter(torch.zeros(d_out))\n",
    "\n",
    "    def set_weight_ratio(self, weight_ratio):\n",
    "        self.W = nn.Parameter(self.W * weight_ratio)\n",
    "\n",
    "    def set_weight_ratio_l2(self, weight_ratio):\n",
    "        self.W = nn.Parameter(self.W * torch.sqrt(weight_ratio))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x @ self.W.T + self.b\n",
    "        return x\n",
    "\n",
    "# TODO\n",
    "class S6(nn.Module): \n",
    "    def __init__(self, d_model=256, d_state=512, dt_rank=32, output_glu=False): # d_model = d_in\n",
    "        \"\"\"Runs the SSM.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dt_rank = dt_rank\n",
    "        self.h = d_model\n",
    "        self.output_glu = output_glu\n",
    "\n",
    "        # x_proj takes in `x` and outputs the input-specific Δ, B, C\n",
    "        self.x_proj = nn.Linear(d_model, dt_rank + d_state * 2, bias=False)\n",
    "        \n",
    "        # dt_proj projects Δ from dt_rank to d_in\n",
    "        self.dt_proj = nn.Linear(dt_rank, d_model, bias=True)\n",
    "\n",
    "        A = repeat(torch.arange(1, d_state + 1), 'n -> d n', d=d_model)\n",
    "        self.A_log = nn.Parameter(torch.log(A))\n",
    "        self.D = nn.Parameter(torch.ones(d_model))\n",
    "\n",
    "        if self.output_glu: ### Changed ###\n",
    "            # position-wise output transform to mix features\n",
    "            self.activation = nn.GELU()  \n",
    "            self.output_linear = nn.Sequential(\n",
    "                nn.Conv1d(self.h, 2*self.h, kernel_size=1),\n",
    "                nn.GLU(dim=-2),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Runs the SSM. See:\n",
    "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
    "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "\n",
    "        Args:\n",
    "            x: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "    \n",
    "        Returns:\n",
    "            output: shape (b, l, d_in)\n",
    "\n",
    "        Official Implementation:\n",
    "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
    "            \n",
    "        \"\"\"\n",
    "        (d_in, n) = self.A_log.shape\n",
    "\n",
    "        # Compute ∆ A B C D, the state space parameters.\n",
    "        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n",
    "        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n",
    "        #                                  and is why Mamba is called **selective** state spaces)\n",
    "        \n",
    "        A = -torch.exp(self.A_log.float())  # shape (d_in, n)\n",
    "        D = self.D.float()\n",
    "\n",
    "        x_dbl = self.x_proj(x)  # (b, l, dt_rank + 2*n)\n",
    "        \n",
    "        (delta, B, C) = x_dbl.split(split_size=[self.dt_rank, n, n], dim=-1)  # delta: (b, l, dt_rank). B, C: (b, l, n)\n",
    "        delta = F.softplus(self.dt_proj(delta))  # (b, l, d_in)\n",
    "        \n",
    "        y = self.selective_scan(x, delta, A, B, C, D)  # This is similar to run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "        \n",
    "        if self.output_glu: ### Changed ###  \n",
    "            y = y.transpose(-1, -2)\n",
    "            y = self.output_linear(self.activation(y))\n",
    "            y = y.transpose(-1, -2)\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "    def selective_scan(self, u, delta, A, B, C, D):\n",
    "        \"\"\"Does selective scan algorithm. See:\n",
    "            - Section 2 State Space Models in the Mamba paper [1]\n",
    "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
    "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
    "\n",
    "        This is the classic discrete state space formula:\n",
    "            x(t + 1) = Ax(t) + Bu(t)\n",
    "            y(t)     = Cx(t) + Du(t)\n",
    "        except B and C (and the step size delta, which is used for discretization) are dependent on the input x(t).\n",
    "    \n",
    "        Args:\n",
    "            u: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
    "            delta: shape (b, l, d_in)\n",
    "            A: shape (d_in, n)\n",
    "            B: shape (b, l, n)\n",
    "            C: shape (b, l, n)\n",
    "            D: shape (d_in,)\n",
    "    \n",
    "        Returns:\n",
    "            output: shape (b, l, d_in)\n",
    "    \n",
    "        Official Implementation:\n",
    "            selective_scan_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L86\n",
    "            Note: I refactored some parts out of `selective_scan_ref` out, so the functionality doesn't match exactly.\n",
    "            \n",
    "        \"\"\"\n",
    "        (b, l, d_in) = u.shape\n",
    "        n = A.shape[1]\n",
    "        \n",
    "        # Discretize continuous parameters (A, B)\n",
    "        # - A is discretized using zero-order hold (ZOH) discretization (see Section 2 Equation 4 in the Mamba paper [1])\n",
    "        # - B is discretized using a simplified Euler discretization instead of ZOH. From a discussion with authors:\n",
    "        #   \"A is the more important term and the performance doesn't change much with the simplification on B\"\n",
    "        deltaA = torch.exp(einsum(delta, A, 'b l d_in, d_in n -> b l d_in n'))\n",
    "        deltaB_u = einsum(delta, B, u, 'b l d_in, b l n, b l d_in -> b l d_in n')\n",
    "        \n",
    "        # Perform selective scan (see scan_SSM() in The Annotated S4 [2])\n",
    "        # Note that the below is sequential, while the official implementation does a much faster parallel scan that\n",
    "        # is additionally hardware-aware (like FlashAttention).\n",
    "        x = torch.zeros((b, d_in, n), device=deltaA.device)\n",
    "        ys = []    \n",
    "        for i in range(l):\n",
    "            x = deltaA[:, i] * x + deltaB_u[:, i]\n",
    "            y = einsum(x, C[:, i, :], 'b d_in n, b n -> b d_in')\n",
    "            ys.append(y)\n",
    "        y = torch.stack(ys, dim=1)  # shape (b, l, d_in)\n",
    "        \n",
    "        y = y + u * D\n",
    "        \n",
    "        return y\n",
    "    \n",
    "# for Transformer\n",
    "class MLPBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    b : batch size\n",
    "    d : embedding size of token\n",
    "    p : vocabraly size (114 or 3)\n",
    "    i : number of heads\n",
    "    h : embedding size of each heads\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_mlp, act_type):\n",
    "        super().__init__()\n",
    "        # bias & layer norm are removed.\n",
    "        self.W_in = nn.Parameter(torch.randn(d_mlp, d_model) / np.sqrt(d_model))\n",
    "        self.b_in = nn.Parameter(torch.zeros(d_mlp))\n",
    "        self.W_out = nn.Parameter(torch.randn(d_model, d_mlp) / np.sqrt(d_model))\n",
    "        self.b_out = nn.Parameter(torch.zeros(d_model))\n",
    "        self.act_type = act_type\n",
    "        # self.ln = LayerNorm(d_mlp, model=self.model)\n",
    "        assert act_type in [\"ReLU\", \"GeLU\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.einsum(\"md,bpd->bpm\", self.W_in, x) + self.b_in\n",
    "        if self.act_type == \"ReLU\":\n",
    "            x = F.relu(x)\n",
    "        elif self.act_type == \"GeLU\":\n",
    "            x = F.gelu(x)\n",
    "        x = torch.einsum(\"dm,bpm->bpd\", self.W_out, x) + self.b_out\n",
    "        return x\n",
    "\n",
    "    def set_weight_ratio(self, weight_ratio):\n",
    "        self.W_in = nn.Parameter(self.W_in * weight_ratio)\n",
    "        self.W_out = nn.Parameter(self.W_out * weight_ratio)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    b : batch size\n",
    "    d : embedding size of token\n",
    "    p : vocabraly size\n",
    "    i : number of heads\n",
    "    h : embedding size of each heads\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model):\n",
    "        super().__init__()\n",
    "        # self.ln1 = LayerNorm(d_model, model=self.model)\n",
    "        self.model = model\n",
    "        self.attn = Attention(d_model, num_heads, d_head, n_ctx)\n",
    "        # self.ln2 = LayerNorm(d_model, model=self.model)\n",
    "        self.mlp = MLPBlock(d_model, d_mlp, act_type)\n",
    "        self.layer_norm = LayerNorm(d_model, model=self.model)\n",
    "        self.hook_attn_out = HookPoint()\n",
    "        self.hook_mlp_out = HookPoint()\n",
    "        self.hook_resid_pre = HookPoint()\n",
    "        self.hook_resid_mid = HookPoint()\n",
    "        self.hook_resid_post = HookPoint()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hook_resid_mid(\n",
    "            x + self.hook_attn_out(self.attn((self.hook_resid_pre(x))))\n",
    "        )\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.hook_resid_post(x + self.hook_mlp_out(self.mlp((x))))\n",
    "        return x\n",
    "\n",
    "    def set_weight_ratio(self, weight_ratio):\n",
    "        self.attn.set_weight_ratio(weight_ratio)\n",
    "        self.mlp.set_weight_ratio(weight_ratio)\n",
    "\n",
    "\n",
    "class InputEmbedder(nn.Module):\n",
    "    \"\"\"Input embedder.\"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "\n",
    "        \"\"\"Initialize the input embedder.\n",
    "\n",
    "    Args:\n",
    "      num_classes: Total number of output classes.\n",
    "      emb_dim: Dimensionality of example and label embeddings.\n",
    "      example_encoding: How to encode example inputs.\n",
    "        'resnet': simple resnet encoding\n",
    "        'linear': flatten and pass through a linear layer\n",
    "        'embedding': pass through an embedding layer\n",
    "      flatten_superpixels: Whether to flatten the output of the resnet (instead\n",
    "        of taking a mean over superpixels).\n",
    "      example_dropout_prob: Dropout probability on example embeddings. Note that\n",
    "        these are applied at both train and test.\n",
    "      concatenate_labels: Whether to concatenate example and label embeddings\n",
    "        into one token for each (example, label) pair, rather than being fed to\n",
    "        the transformer as two separate tokens.\n",
    "      use_positional_encodings: Whether to use positional encoding.\n",
    "      positional_dropout_prob: Positional dropout probability.\n",
    "      name: Optional name for the module.\n",
    "    \"\"\"\n",
    "        super(InputEmbedder, self).__init__()\n",
    "        self.num_labels = conf.d_vocab\n",
    "        self.emb_dim = conf.d_emb\n",
    "        self.p_dim = conf.p_dim\n",
    "        self.emb_dim_content = self.emb_dim - self.p_dim\n",
    "        self.n_ctx = conf.n_ctx\n",
    "\n",
    "        self.Emb = nn.Linear(self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.label_embs = nn.Parameter(\n",
    "            torch.randn(self.num_labels, self.emb_dim_content) / np.sqrt(self.emb_dim_content)\n",
    "        )\n",
    "\n",
    "    def forward(self, examples, labels, tasks=None):\n",
    "        \"\"\"Call to the input embedder.\n",
    "\n",
    "        Args:\n",
    "          examples: input sequence of shape\n",
    "            [batch_size, seq_len, height, width, channels]\n",
    "          labels: input sequence of shape [batch_size, seq_len]\n",
    "          tasks: input sequence of shape [batch_size, seq_len]\n",
    "\n",
    "        Returns:\n",
    "          outputs: output of the transformer tower\n",
    "            of shape [batch_size, seq_len, channels].\n",
    "        \"\"\"\n",
    "        # Encode the example inputs into shape (B, SS, E)\n",
    "        B, SS, D = examples.shape\n",
    "        # pos encoding\n",
    "        pos_enc = F.one_hot(torch.arange(start=0,end=self.n_ctx+1,step=2), num_classes=self.p_dim).repeat(B,1,1).to(examples.device)\n",
    "        h_example = torch.cat([examples, pos_enc], dim=2)\n",
    "\n",
    "        # Embed the labels.\n",
    "        labels_to_embed = labels\n",
    "        h_label = self.label_embs[labels_to_embed]  # (B, SS, D)\n",
    "        pos_enc = F.one_hot(torch.arange(start=1,end=self.n_ctx+1,step=2), num_classes=self.p_dim).repeat(B,1,1).to(examples.device)\n",
    "        h_label = torch.cat([h_label, pos_enc], dim=2) # (B, SS, E)\n",
    "        \n",
    "        hh = torch.empty(\n",
    "            (h_example.shape[0], h_example.shape[1] * 2 - 1, h_example.shape[2]),\n",
    "            dtype=h_example.dtype,\n",
    "        ).to(h_example.device)\n",
    "        \n",
    "        hh[:, 0::2] = h_example\n",
    "        hh[:, 1::2] = h_label[:, :-1]\n",
    "\n",
    "        return hh\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, embedder, config):\n",
    "        super().__init__()\n",
    "        num_layers = config.num_layers\n",
    "        d_model = config.d_emb\n",
    "        d_mlp = config.d_emb * 4\n",
    "        d_head = config.d_emb // config.num_heads\n",
    "        num_heads = config.num_heads\n",
    "        n_ctx = config.n_ctx\n",
    "        act_type = config.act_type\n",
    "        use_cache = config.use_cache\n",
    "        use_ln = config.use_ln\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "        d_vocab = config.d_vocab\n",
    "\n",
    "        self.embedder = embedder\n",
    "        # self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model=[self]\n",
    "                )\n",
    "                for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        # self.ln = LayerNorm(d_model, model=[self])\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module) == HookPoint:\n",
    "                module.give_name(name)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        x = self.embedder(x, labels,)\n",
    "        # x = self.pos_embed(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if \"hook\" in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks(\"fwd\")\n",
    "            hp.remove_hooks(\"bwd\")\n",
    "\n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name + \"_grad\"] = tensor[0].detach()\n",
    "\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, \"fwd\")\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, \"bwd\")\n",
    "\n",
    "class TransformerICL(nn.Module):\n",
    "    def __init__(self, embedder, config):\n",
    "        super().__init__()\n",
    "        self.num_layers = config.num_layers\n",
    "        self.num_atten_layer = config.num_atten_layer\n",
    "        d_model = config.d_emb\n",
    "        self.d_mlp = config.d_mlp\n",
    "        d_head = config.d_emb // config.num_heads\n",
    "        num_heads = config.num_heads\n",
    "        n_ctx = config.n_ctx\n",
    "        act_type = config.act_type\n",
    "        use_cache = config.use_cache\n",
    "        use_ln = config.use_ln\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "        d_vocab = config.d_vocab\n",
    "        self.seq_model = config.seq_model # \"Attention\" , \"LSTM\", \"Mamba\", \"RNN\", \"S4\", \"LinerAttention\"\n",
    "        self.d_emb = config.d_emb\n",
    "        self.use_scaled_attention = config.use_scaled_attention\n",
    "\n",
    "        self.embedder = embedder\n",
    "        # self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        if self.seq_model == \"Attention\":\n",
    "            self.atten_list = nn.ModuleList(\n",
    "                [\n",
    "                    Attention(d_model, num_heads, d_head, n_ctx, scaled=self.use_scaled_attention) for i in range(self.num_atten_layer)\n",
    "                ]\n",
    "            )\n",
    "        elif self.seq_model == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(self.d_emb, d_model, self.num_atten_layer, batch_first=True)\n",
    "        elif self.seq_model == \"RNN\":\n",
    "            self.rnn = nn.RNN(self.d_emb, d_model, self.num_atten_layer, batch_first=True)\n",
    "        elif self.seq_model == \"Mamba\":\n",
    "            self.atten_list = nn.ModuleList(\n",
    "                [\n",
    "                    Mamba(self.d_emb, d_model) for i in range(self.num_atten_layer)\n",
    "                ]\n",
    "            )\n",
    "        elif self.seq_model == \"S6\":\n",
    "            self.atten_list = nn.ModuleList(\n",
    "                [\n",
    "                    S6(self.d_emb, d_model) for i in range(self.num_atten_layer)\n",
    "                ]\n",
    "            )\n",
    "        self.mlp_list = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(d_model, d_model) for i in range(self.num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model, d_vocab)\n",
    "        self.use_ln = use_ln\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module) == HookPoint:\n",
    "                module.give_name(name)\n",
    "\n",
    "    def forward(self, x, labels, tasks=None):\n",
    "        x = self.embedder(x, labels, tasks)\n",
    "        if self.seq_model == \"RNN\" or self.seq_model == \"LSTM\":\n",
    "            x, _ = self.rnn(x)\n",
    "        else:\n",
    "            for atten in self.atten_list:\n",
    "                x = atten(x) + x\n",
    "        for mlp in self.mlp_list:\n",
    "            x = mlp(x) \n",
    "            x = F.relu(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if \"hook\" in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks(\"fwd\")\n",
    "            hp.remove_hooks(\"bwd\")\n",
    "\n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name + \"_grad\"] = tensor[0].detach()\n",
    "\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, \"fwd\")\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, \"bwd\")\n",
    "                \n",
    "    def get_attention_matrix(self, layer):\n",
    "        return self.atten_list[layer].get_attention_matrix()\n",
    "    \n",
    "                \n",
    "                \n",
    "    \n",
    "class MultiTaskInputEmbedderV1(nn.Module):\n",
    "    \"\"\"Input embedder.\"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "\n",
    "        \"\"\"Initialize the input embedder.\n",
    "\n",
    "    Args:\n",
    "      num_classes: Total number of output classes.\n",
    "      emb_dim: Dimensionality of example and label embeddings.\n",
    "      example_encoding: How to encode example inputs.\n",
    "        'resnet': simple resnet encoding\n",
    "        'linear': flatten and pass through a linear layer\n",
    "        'embedding': pass through an embedding layer\n",
    "      flatten_superpixels: Whether to flatten the output of the resnet (instead\n",
    "        of taking a mean over superpixels).\n",
    "      example_dropout_prob: Dropout probability on example embeddings. Note that\n",
    "        these are applied at both train and test.\n",
    "      concatenate_labels: Whether to concatenate example and label embeddings\n",
    "        into one token for each (example, label) pair, rather than being fed to\n",
    "        the transformer as two separate tokens.\n",
    "      use_positional_encodings: Whether to use positional encoding.\n",
    "      positional_dropout_prob: Positional dropout probability.\n",
    "      name: Optional name for the module.\n",
    "    \"\"\"\n",
    "        super(MultiTaskInputEmbedderV1, self).__init__()\n",
    "        self._num_classes = conf.d_vocab\n",
    "        self._emb_dim = conf.d_emb\n",
    "        self.p_dim = conf.p_dim\n",
    "        self.num_tasks = conf.num_tasks\n",
    "\n",
    "        self.Emb = nn.Linear(self._emb_dim, self._emb_dim)\n",
    "\n",
    "        self.label_embs = nn.Parameter(\n",
    "            torch.randn(self._num_classes, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "        \n",
    "        self.task_embs = nn.Parameter(\n",
    "            torch.randn(self.num_tasks, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, examples, labels, tasks):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            examples (_type_): _description_\n",
    "            labels (_type_): _description_\n",
    "            tasks (_type_): _description_\n",
    "            is_training (bool): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # Encode the example inputs into shape (B, SS, E)\n",
    "        B, SS, D = examples.shape\n",
    "        examples = examples.view(B, SS, D)\n",
    "        # pos encoding\n",
    "        pos_enc = F.one_hot(torch.arange(SS), num_classes=self.p_dim).repeat(B,1,1).to(examples.device)\n",
    "        h_example = torch.cat([examples, pos_enc], dim=2) # (B, SS, E)\n",
    "        \n",
    "        # Embed the labels. (B, SS, 1) -> (B, SS, E)\n",
    "        h_label = self.label_embs[labels]  # (B, SS, E)\n",
    "        h_label = h_label.view(B, SS, self._emb_dim) #(B, SS, E)\n",
    "        \n",
    "        # task embedding (B, SS) -> (B, SS, E)　一つだけ取ってくる\n",
    "        tmp_task = tasks\n",
    "        task_embs = self.task_embs[tmp_task] # (B, 1, E)\n",
    "        task_embs = task_embs.view(B, SS, self._emb_dim) #(B, SS, E)\n",
    "        \n",
    "        hh = torch.empty((B, SS * 3 -1 ,  self._emb_dim), dtype=h_example.dtype, device=h_example.device)\n",
    "        # hh = torch.zeros((B, (SS * 2 ),  h_example.shape[2]), dtype=h_example.dtype, device=h_example.device )\n",
    "        hh[:, 0::3, :] = task_embs\n",
    "        hh[:, 1::3] = h_example\n",
    "        hh[:, 2::3] = h_label[:, :-1]\n",
    "\n",
    "        # last label remove\n",
    "        # hh = hh[:, :-1]\n",
    "        \n",
    "\n",
    "        return hh\n",
    "\n",
    "class MultiTaskInputEmbedderV2(nn.Module):\n",
    "    \"\"\"Input embedder.\"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "\n",
    "        \"\"\"Initialize the input embedder.\n",
    "\n",
    "    Args:\n",
    "      num_classes: Total number of output classes.\n",
    "      emb_dim: Dimensionality of example and label embeddings.\n",
    "      example_encoding: How to encode example inputs.\n",
    "        'resnet': simple resnet encoding\n",
    "        'linear': flatten and pass through a linear layer\n",
    "        'embedding': pass through an embedding layer\n",
    "      flatten_superpixels: Whether to flatten the output of the resnet (instead\n",
    "        of taking a mean over superpixels).\n",
    "      example_dropout_prob: Dropout probability on example embeddings. Note that\n",
    "        these are applied at both train and test.\n",
    "      concatenate_labels: Whether to concatenate example and label embeddings\n",
    "        into one token for each (example, label) pair, rather than being fed to\n",
    "        the transformer as two separate tokens.\n",
    "      use_positional_encodings: Whether to use positional encoding.\n",
    "      positional_dropout_prob: Positional dropout probability.\n",
    "      name: Optional name for the module.\n",
    "    \"\"\"\n",
    "        super(MultiTaskInputEmbedderV2, self).__init__()\n",
    "        self._num_classes = conf.d_vocab\n",
    "        self._emb_dim = conf.d_emb\n",
    "        self.p_dim = conf.p_dim\n",
    "        self.num_tasks = conf.num_tasks\n",
    "\n",
    "        self.Emb = nn.Linear(self._emb_dim, self._emb_dim)\n",
    "\n",
    "        self.label_embs = nn.Parameter(\n",
    "            torch.randn(self._num_classes, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "        \n",
    "        self.task_embs = nn.Parameter(\n",
    "            torch.randn(self.num_tasks, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, examples, labels, tasks):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            examples (_type_): _description_\n",
    "            labels (_type_): _description_\n",
    "            tasks (_type_): _description_\n",
    "            is_training (bool): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # Encode the example inputs into shape (B, SS, E)\n",
    "        B, SS, D = examples.shape\n",
    "        examples = examples.view(B, SS, D)\n",
    "        # pos encoding\n",
    "        pos_enc = F.one_hot(torch.arange(SS), num_classes=self.p_dim).repeat(B,1,1).to(examples.device)\n",
    "        h_example = torch.cat([examples, pos_enc], dim=2) # (B, SS, E)\n",
    "        \n",
    "        # Embed the labels. (B, SS, 1) -> (B, SS, E)\n",
    "        h_label = self.label_embs[labels]  # (B, SS, E)\n",
    "        h_label = h_label.view(B, SS, self._emb_dim) #(B, SS, E)\n",
    "        \n",
    "        # task embedding (B, SS) -> (B, 1, E)　一つだけ取ってくる\n",
    "        tmp_task = tasks[:, -1]\n",
    "        task_embs = self.task_embs[tmp_task] # (B, 1, E)\n",
    "        hh = torch.empty((B, SS * 2 ,  self._emb_dim), dtype=h_example.dtype, device=h_example.device)\n",
    "        # hh = torch.zeros((B, (SS * 2 ),  h_example.shape[2]), dtype=h_example.dtype, device=h_example.device )\n",
    "        hh[:, 0, :] = task_embs\n",
    "        hh[:, 1::2] = h_example\n",
    "        hh[:, 2::2] = h_label[:, :-1]\n",
    "\n",
    "        # last label remove\n",
    "        # hh = hh[:, :-1]\n",
    "        \n",
    "\n",
    "        return hh\n",
    "    \n",
    "class MultiTaskInputEmbedderV3(nn.Module):\n",
    "    \"\"\"Input embedder.\"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "\n",
    "        \"\"\"Initialize the input embedder.\n",
    "\n",
    "    Args:\n",
    "      num_classes: Total number of output classes.\n",
    "      emb_dim: Dimensionality of example and label embeddings.\n",
    "      example_encoding: How to encode example inputs.\n",
    "        'resnet': simple resnet encoding\n",
    "        'linear': flatten and pass through a linear layer\n",
    "        'embedding': pass through an embedding layer\n",
    "      flatten_superpixels: Whether to flatten the output of the resnet (instead\n",
    "        of taking a mean over superpixels).\n",
    "      example_dropout_prob: Dropout probability on example embeddings. Note that\n",
    "        these are applied at both train and test.\n",
    "      concatenate_labels: Whether to concatenate example and label embeddings\n",
    "        into one token for each (example, label) pair, rather than being fed to\n",
    "        the transformer as two separate tokens.\n",
    "      use_positional_encodings: Whether to use positional encoding.\n",
    "      positional_dropout_prob: Positional dropout probability.\n",
    "      name: Optional name for the module.\n",
    "    \"\"\"\n",
    "        super(MultiTaskInputEmbedderV3, self).__init__()\n",
    "        self._num_classes = conf.d_vocab\n",
    "        self._emb_dim = conf.d_emb\n",
    "        self.p_dim = conf.p_dim\n",
    "        self.num_tasks = conf.num_tasks\n",
    "\n",
    "        self.Emb = nn.Linear(self._emb_dim, self._emb_dim)\n",
    "\n",
    "        self.label_embs = nn.Parameter(\n",
    "            torch.randn(self._num_classes, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "        \n",
    "        self.task_embs = nn.Parameter(\n",
    "            torch.randn(self.num_tasks, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, examples, labels, tasks):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            examples (_type_): _description_\n",
    "            labels (_type_): _description_\n",
    "            tasks (_type_): _description_\n",
    "            is_training (bool): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # Encode the example inputs into shape (B, SS, E)\n",
    "        B, SS, D = examples.shape\n",
    "        examples = examples.view(B, SS, D)\n",
    "        # pos encoding\n",
    "        pos_enc = F.one_hot(torch.arange(SS), num_classes=self.p_dim).repeat(B,1,1).to(examples.device)\n",
    "        h_example = torch.cat([examples, pos_enc], dim=2) # (B, SS, E)\n",
    "        \n",
    "        # Embed the labels. (B, SS, 1) -> (B, SS, E)\n",
    "        h_label = self.label_embs[labels]  # (B, SS, E)\n",
    "        h_label = h_label.view(B, SS, self._emb_dim) #(B, SS, E)\n",
    "        \n",
    "        # task embedding (B, SS) -> (B, 1, E)　一つだけ取ってくる\n",
    "        tmp_task = tasks[:, -1]\n",
    "        task_embs = self.task_embs[tmp_task] # (B, 1, E)\n",
    "        hh = torch.empty((B, SS * 2 - 1,  self._emb_dim), dtype=h_example.dtype, device=h_example.device)\n",
    "        # hh = torch.zeros((B, (SS * 2 ),  h_example.shape[2]), dtype=h_example.dtype, device=h_example.device )\n",
    "        # hh[:, 0, :] = task_embs\n",
    "        hh[:, 0::2] = h_example\n",
    "        hh[:, 1::2] = h_label[:, :-1]\n",
    "\n",
    "        # last label remove\n",
    "        # hh = hh[:, :-1]\n",
    "        \n",
    "\n",
    "        return hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visalize_attention(model, layer_i):\n",
    "    attn_matrix = model.get_attention_matrix(layer_i)\n",
    "    num_heads = attn_matrix.size(0)\n",
    "    fig, ax = plt.subplots(num_heads, 1, figsize=(5*num_heads, 5))\n",
    "    if num_heads == 1:\n",
    "        ax = [ax]\n",
    "    for j in range(num_heads):\n",
    "        ax[j].imshow(attn_matrix[j].detach().cpu().numpy(), cmap=\"Blues\")\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataconfig = MainConfig.traindataconfig\n",
    "icldataconfig = MainConfig.icldataconfig\n",
    "iwldataconfig = MainConfig.iwldataconfig\n",
    "icl2dataconfig = MainConfig.icl2dataconfig\n",
    "trainconfig = MainConfig.trainconfig\n",
    "modelconfig = MainConfig.modelconfig\n",
    "\n",
    "\n",
    "Dataset = SamplingDataset(traindataconfig)\n",
    "\n",
    "trainloader = MultiTaskSamplingLoader(traindataconfig, dataset=Dataset)\n",
    "train_seq_generator = trainloader.get_seq\n",
    "train_dataset = IterDataset(train_seq_generator)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "iclloader = MultiTaskSamplingLoader(icldataconfig, dataset=Dataset)\n",
    "icl_seq_generator = iclloader.get_seq\n",
    "icl_dataset = IterDataset(icl_seq_generator)\n",
    "icl_dataloader = torch.utils.data.DataLoader(icl_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "iwlloader = MultiTaskSamplingLoader(iwldataconfig, dataset=Dataset)\n",
    "iwl_seq_generator = iwlloader.get_seq\n",
    "iwl_dataset = IterDataset(iwl_seq_generator)\n",
    "iwl_dataloader = torch.utils.data.DataLoader(iwl_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "icl2loader = MultiTaskSamplingLoader(icl2dataconfig, dataset=Dataset)\n",
    "icl2_seq_generator = icl2loader.get_seq\n",
    "icl2_dataset = IterDataset(icl2_seq_generator)\n",
    "icl2_dataloader = torch.utils.data.DataLoader(icl2_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"weight\"\n",
    "embedder = MultiTaskInputEmbedderV3(modelconfig)\n",
    "model = TransformerICL(embedder, modelconfig)\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "\n",
    "model.eval()\n",
    "data_dict = next(iter(train_dataloader))\n",
    "model(data_dict[\"examples\"], data_dict[\"labels\"], data_dict[\"tasks\"])\n",
    "for layer_i in range(modelconfig.num_atten_layer):\n",
    "    fig = visalize_attention(model, layer_i)\n",
    "    fig.savefig(f\"attention_{layer_i}.png\")\n",
    "    plt.close(fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
