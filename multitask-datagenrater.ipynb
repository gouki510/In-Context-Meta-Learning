{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 13 12:56:29 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.146.02             Driver Version: 535.146.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  | 00000000:21:00.0 Off |                  Off |\n",
      "| 72%   87C    P2             199W / 200W |  24828MiB / 49140MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               On  | 00000000:41:00.0 Off |                  Off |\n",
      "| 45%   72C    P2              95W / 200W |   1145MiB / 49140MiB |     10%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000               On  | 00000000:43:00.0 Off |                  Off |\n",
      "| 56%   80C    P2             181W / 200W |  44734MiB / 49140MiB |     67%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class SamplingDataset(object):\n",
    "  def __init__(self,conf):\n",
    "    self.num_classes = conf.num_classes\n",
    "    self.dim = conf.dim\n",
    "    self.num_labels = conf.num_labels\n",
    "    self.mu, self.labels = self._get_data()\n",
    "\n",
    "  def _get_data(self):\n",
    "    mu = torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(self.num_classes,self.dim))\n",
    "    labels = torch.randint(self.num_labels, size=(self.num_classes,1))\n",
    "    return mu, labels\n",
    "\n",
    "class MultiTaskSamplingLoader(DataLoader):\n",
    "\n",
    "  def __init__(self,conf, dataset):\n",
    "    self.dataset = dataset\n",
    "    self.mu, self.labels = self.dataset.mu, self.dataset.labels\n",
    "    self.data_type = conf.data_type\n",
    "    self.num_seq = conf.num_seq\n",
    "    self.alpha = conf.alpha\n",
    "    self.num_classes = conf.num_classes\n",
    "    self.num_task = conf.num_tasks\n",
    "    self.num_labels = conf.num_labels\n",
    "    self.task_ways = conf.task_ways\n",
    "    self.item_ways = conf.item_ways\n",
    "    self.p_bursty = conf.p_bursty\n",
    "    self.p_icl = conf.p_icl\n",
    "    self.eps = conf.eps\n",
    "    self.dim = conf.dim\n",
    "    if self.item_ways != 0 or self.task_ways != 0:\n",
    "      assert self.num_seq % self.item_ways == 0 and self.num_seq % self.task_ways == 0\n",
    "    if self.item_ways == 0 or self.task_ways == 0:\n",
    "      self.p_bursty = 0\n",
    "    prob = np.array([1/((k+1)**self.alpha) for k in range(self.num_classes)])\n",
    "    self.prob = prob/prob.sum()\n",
    "\n",
    "  def get_seq(self):\n",
    "    while True:\n",
    "      if self.data_type==\"bursty\":\n",
    "        if self.p_bursty > np.random.rand():\n",
    "          # choise few shot tasks\n",
    "          num_few_shot_task = self.num_seq//self.task_ways\n",
    "          few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "          tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "          # print(tasks.shape)\n",
    "          \n",
    "          # choise few shot items\n",
    "          num_few_shot_class = self.num_seq//self.item_ways\n",
    "          few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "          mus = self.mu[few_shot_class]\n",
    "          mus = np.repeat(mus, self.item_ways, axis=0) # expand ways\n",
    "          \n",
    "          # choice few shot labels\n",
    "          labels = self.labels[few_shot_class]\n",
    "          labels = np.repeat(labels, self.item_ways, axis=0) # expand ways\n",
    "        \n",
    "          \n",
    "          # classes \n",
    "          classes = np.repeat(few_shot_class, self.item_ways)\n",
    "          # add noise\n",
    "          x = self.add_noise(mus)\n",
    "          # permutation shuffle\n",
    "          ordering = np.random.permutation(self.num_seq)\n",
    "          x = x[ordering]\n",
    "          labels = labels[ordering]\n",
    "          classes = classes[ordering]\n",
    "          task_ordering = np.random.permutation(self.num_seq)\n",
    "          tasks = tasks[task_ordering]\n",
    "          \n",
    "          labels = (labels + tasks) % self.num_labels\n",
    "          \n",
    "          # select query labels\n",
    "          query_class = np.random.choice(few_shot_class, 1)\n",
    "          query_task = np.random.choice(few_shot_task, 1)\n",
    "          query_label = (self.labels[query_class] + query_task) % self.num_labels\n",
    "          query_mu = self.mu[query_class]\n",
    "          query_x = self.add_noise(query_mu)\n",
    "          # concat\n",
    "          x = torch.cat([x, query_x])\n",
    "          labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "          tasks = torch.cat([torch.tensor(tasks).flatten(), torch.tensor(query_task).flatten()])\n",
    "          \n",
    "          yield {\n",
    "              \"tasks\":tasks,\n",
    "              \"examples\":x.to(torch.float32),\n",
    "              \"labels\":labels,\n",
    "              \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "          }\n",
    "          \n",
    "        else:\n",
    "          # rank frequency\n",
    "          num_few_shot_task = self.num_seq//self.task_ways\n",
    "          few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "          tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "          \n",
    "          classes = np.random.choice(self.num_classes, self.num_seq+1, p=self.prob)\n",
    "          mus = self.mu[classes]\n",
    "          labels = self.labels[classes]\n",
    "          x = self.add_noise(mus)\n",
    "          # permutation shuffle\n",
    "          ordering = np.random.permutation(self.num_seq+1)\n",
    "          x = x[ordering]\n",
    "          labels = labels[ordering]\n",
    "          labels = (labels + tasks) % self.num_labels\n",
    "          classes = classes[ordering]\n",
    "          tasks = tasks[ordering]\n",
    "          \n",
    "\n",
    "          yield {\n",
    "              \"tasks\":tasks,\n",
    "              \"examples\":x.to(torch.float32),\n",
    "              \"labels\":labels.flatten(),\n",
    "              \"classes\" : torch.from_numpy(classes)\n",
    "          }\n",
    "\n",
    "      elif self.data_type == \"no_support\":\n",
    "          num_few_shot_task = self.num_seq//self.task_ways\n",
    "          few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "          tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "        \n",
    "          # rank frequency\n",
    "          classes = np.random.choice(self.num_classes, self.num_seq, p=self.prob)\n",
    "          mus = self.mu[classes]\n",
    "          # random label\n",
    "          labels = np.random.randint(self.num_labels, size=(self.num_seq,1))\n",
    "          x = self.add_noise(mus)\n",
    "          # permutation shuffle\n",
    "          ordering = np.random.permutation(self.num_seq)\n",
    "          x = x[ordering]\n",
    "          labels = labels[ordering]\n",
    "          classes = classes[ordering]\n",
    "          tasks = tasks[ordering]\n",
    "          \n",
    "          # select query labels\n",
    "          query_class = np.random.choice(self.num_classes, 1)\n",
    "          query_task = np.random.choice(few_shot_task, 1)\n",
    "          query_label = self.labels[query_class]\n",
    "          query_label = (query_label + query_task) % self.num_labels\n",
    "          query_mu = self.mu[query_class]\n",
    "          query_mu = self.add_noise(query_mu)\n",
    "          \n",
    "          # concat\n",
    "          x = torch.cat([x, query_mu])\n",
    "          labels = torch.cat([torch.from_numpy(labels).flatten(), query_label.flatten()])\n",
    "          tasks = torch.cat([torch.tensor(tasks).flatten(), torch.tensor(query_task).flatten()])\n",
    "          classes = np.concatenate([classes, query_class])\n",
    "\n",
    "          yield {\n",
    "              \"tasks\": tasks,\n",
    "              \"examples\":x.to(torch.float32),\n",
    "              \"labels\":labels.flatten(),\n",
    "              \"classes\" : torch.from_numpy(classes)\n",
    "          }\n",
    "          \n",
    "      elif self.data_type == \"holdout\":\n",
    "        # choise few shot tasks\n",
    "        num_few_shot_task = self.num_seq//self.task_ways\n",
    "        few_shot_task = np.random.choice(self.num_task, num_few_shot_task, replace=False)\n",
    "        tasks = np.repeat(few_shot_task, self.task_ways, axis=0).reshape(-1,1)\n",
    "        false_tasks = np.random.choice(self.num_task, 1, replace=False)\n",
    "        # print(tasks.shape)\n",
    "        \n",
    "        # choise few shot items\n",
    "        num_few_shot_class = self.num_seq//self.item_ways\n",
    "        few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "        mus = self.mu[few_shot_class]\n",
    "        mus = np.repeat(mus, self.item_ways, axis=0) # expand ways\n",
    "        \n",
    "        # choice few shot labels\n",
    "        labels = self.labels[few_shot_class]\n",
    "        labels = np.repeat(labels, self.item_ways, axis=0) # expand ways\n",
    "        \n",
    "        classes = np.repeat(few_shot_class, self.item_ways)\n",
    "        \n",
    "        # add noise\n",
    "        x = self.add_noise(mus)\n",
    "        # permutation shuffle\n",
    "        ordering = np.random.permutation(self.num_seq)\n",
    "        mus = mus[ordering]\n",
    "        x = x[ordering]\n",
    "        labels = labels[ordering]\n",
    "        classes = classes[ordering]\n",
    "        tasks = tasks[ordering]\n",
    "        \n",
    "        labels = (labels + tasks) % self.num_labels\n",
    "        \n",
    "        # select query labels\n",
    "        query_class = np.random.choice(few_shot_class, 1)\n",
    "        query_task = np.random.choice(few_shot_task, 1)\n",
    "        query_label = (self.labels[query_class] + query_task) % self.num_labels\n",
    "        query_mu = self.mu[query_class]\n",
    "        query_x = self.add_noise(query_mu)\n",
    "        # concat\n",
    "        x = torch.cat([x, query_x])\n",
    "        labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "        tasks = torch.cat([torch.tensor(tasks).flatten(), torch.tensor(false_tasks).flatten()])\n",
    "          \n",
    "        \n",
    "        \n",
    "        yield {\n",
    "            \"tasks\":tasks,\n",
    "            \"examples\":x.to(torch.float32),\n",
    "            \"labels\":labels,\n",
    "            \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "        }\n",
    "\n",
    "      elif self.data_type == \"flip\":\n",
    "        # choise few shot example\n",
    "        num_few_shot_class = self.num_seq//self.ways\n",
    "        few_shot_class = np.random.choice(self.num_classes, num_few_shot_class, replace=False)\n",
    "        mus = self.mu[few_shot_class]\n",
    "        mus = np.repeat(mus, self.ways, axis=0) # expand ways\n",
    "        classes = np.repeat(few_shot_class, self.ways)\n",
    "        # label flip\n",
    "        labels = (self.labels[classes] + 1) % self.num_labels\n",
    "        # add noise\n",
    "        x = self.add_noise(mus)\n",
    "        # permutation shuffle\n",
    "        ordering = np.random.permutation(self.num_seq)\n",
    "        x = x[ordering]\n",
    "        labels = labels[ordering]\n",
    "        classes = classes[ordering]\n",
    "        # select query labels\n",
    "        query_class = np.random.choice(few_shot_class, 1)\n",
    "        query_label = (self.labels[query_class] + 1) % self.num_labels\n",
    "        query_mu = self.mu[query_class]\n",
    "        query_x = self.add_noise(query_mu)\n",
    "        # concat\n",
    "        x = torch.cat([x, query_x])\n",
    "        labels = torch.cat([labels.flatten(), query_label.flatten()])\n",
    "        \n",
    "        yield {\n",
    "            \"examples\":x.to(torch.float32),\n",
    "            \"labels\":labels,\n",
    "            \"classes\" : torch.cat([torch.from_numpy(classes).flatten(), torch.from_numpy(query_class).flatten()])\n",
    "        }\n",
    "    \n",
    "  \n",
    "\n",
    "  def add_noise(self, x):\n",
    "    x = (x+self.eps*torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(x.shape)))/(np.sqrt(1+self.eps**2))\n",
    "    # x = (x+self.eps*np.random.normal(mean=0, std=np.sqrt(1/self.dim), size=(x.shape[0],1)))/(np.sqrt(1+self.eps**2))\n",
    "    return x\n",
    "  \n",
    "  def _get_novel_class_seq(self,num_class):\n",
    "    mu = torch.normal(mean=0, std=math.sqrt(1/self.dim), size=(num_class,self.dim))\n",
    "    labels = torch.randint(self.num_labels, size=(num_class,1))\n",
    "    return mu, labels\n",
    "\n",
    "class IterDataset(IterableDataset):\n",
    "    def __init__(self, generator):\n",
    "        self.generator = generator\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class TransformerConfig:\n",
    "  num_layers: int = 2\n",
    "  d_vocab: int = 32\n",
    "  d_model: int = 128\n",
    "  d_mlp: int = 128\n",
    "  d_head: int = 128\n",
    "  num_heads: int = 1\n",
    "  # n_ctx: int = int((9*2+1)*3-1)\n",
    "  n_ctx: int = int(9*2)\n",
    "  act_type: str = \"ReLU\"\n",
    "  use_cache: bool = False\n",
    "  use_ln: bool = True\n",
    "  p_dim: int = 65\n",
    "  d_emb: int = 128\n",
    "  num_tasks:int = 3\n",
    "  num_seq_per_task:int = 8\n",
    "\n",
    "@dataclass\n",
    "class TrainDataConfig:\n",
    "  num_classes: int = 10\n",
    "  dim: int = 63\n",
    "  num_labels: int = 6\n",
    "  eps: float = 0.1\n",
    "  alpha: float = 0\n",
    "  item_ways: int = 1\n",
    "  num_seq: int = 8\n",
    "  p_bursty: float = 1\n",
    "  data_type: str = \"bursty\" # bursty, holdout, no_support, flip\n",
    "  num_holdout_classes: int = 2\n",
    "  num_tasks: int = 3\n",
    "  task_ways: int = 8\n",
    "  p_icl=0\n",
    "\n",
    "@dataclass\n",
    "class IWLDataConfig(TrainDataConfig):\n",
    "  data_type: str = \"no_support\" # bursty, holdout, no_support, flip\n",
    "\n",
    "@dataclass\n",
    "class ICLDataConfig(TrainDataConfig):\n",
    "  data_type: str = \"holdout\" # bursty, holdout, no_support, flip\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ICL2DataConfig(TrainDataConfig):\n",
    "  data_type: str = \"flip\" # bursty, holdout, no_support, flip\n",
    "  \n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "  batch_size: int = 3\n",
    "  optimize_step: int = int(5e4)\n",
    "  lr: float = 0.01\n",
    "  optimizer: str = \"sgd\" # adam, sgd, adamw\n",
    "\n",
    "@dataclass\n",
    "class MainConfig:\n",
    "  traindataconfig : TrainDataConfig = TrainDataConfig()\n",
    "  icldataconfig: ICLDataConfig = ICLDataConfig()\n",
    "  iwldataconfig: IWLDataConfig = IWLDataConfig()\n",
    "  icl2dataconfig: ICL2DataConfig = ICL2DataConfig()\n",
    "  modelconfig: TransformerConfig = TransformerConfig()\n",
    "  trainconfig: TrainConfig = TrainConfig()\n",
    "  device: str = \"cuda:0\"\n",
    "# define config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "task\n",
      " tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "train_class\n",
      " tensor([[3, 5, 4, 9, 0, 6, 7, 2, 3],\n",
      "        [4, 6, 5, 3, 1, 8, 2, 7, 4],\n",
      "        [6, 4, 5, 9, 8, 2, 3, 1, 3]])\n",
      "train_label\n",
      " tensor([[2, 1, 5, 4, 2, 4, 0, 5, 2],\n",
      "        [5, 4, 1, 2, 2, 5, 5, 0, 5],\n",
      "        [3, 4, 0, 3, 4, 4, 1, 1, 1]])\n",
      "ICL\n",
      "task\n",
      " tensor([[2, 2, 2, 2, 2, 2, 2, 2, 0],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "train_class\n",
      " tensor([[1, 4, 7, 9, 5, 3, 2, 8, 3],\n",
      "        [9, 7, 6, 2, 3, 4, 8, 5, 3],\n",
      "        [4, 3, 9, 5, 7, 0, 6, 1, 5]])\n",
      "train_label\n",
      " tensor([[2, 5, 0, 4, 1, 2, 5, 5, 2],\n",
      "        [4, 0, 4, 5, 2, 5, 5, 1, 2],\n",
      "        [4, 1, 3, 0, 5, 1, 3, 1, 0]])\n",
      "IWL\n",
      "example torch.Size([3, 9, 63])\n",
      "task\n",
      " tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "train_class\n",
      " tensor([[2, 4, 7, 1, 3, 9, 5, 5, 7],\n",
      "        [9, 6, 7, 6, 2, 8, 0, 2, 2],\n",
      "        [1, 7, 5, 4, 3, 4, 9, 2, 6]])\n",
      "train_label\n",
      " tensor([[0, 5, 0, 2, 2, 5, 4, 3, 0],\n",
      "        [2, 4, 3, 3, 3, 3, 1, 0, 4],\n",
      "        [2, 0, 0, 0, 2, 3, 0, 5, 4]])\n"
     ]
    }
   ],
   "source": [
    "traindataconfig = MainConfig.traindataconfig\n",
    "icldataconfig = MainConfig.icldataconfig\n",
    "iwldataconfig = MainConfig.iwldataconfig\n",
    "icl2dataconfig = MainConfig.icl2dataconfig\n",
    "trainconfig = MainConfig.trainconfig\n",
    "\n",
    "Dataset = SamplingDataset(traindataconfig)\n",
    "\n",
    "trainloader = MultiTaskSamplingLoader(traindataconfig, dataset=Dataset)\n",
    "train_seq_generator = trainloader.get_seq\n",
    "train_dataset = IterDataset(train_seq_generator)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "iclloader = MultiTaskSamplingLoader(icldataconfig, dataset=Dataset)\n",
    "icl_seq_generator = iclloader.get_seq\n",
    "icl_dataset = IterDataset(icl_seq_generator)\n",
    "icl_dataloader = torch.utils.data.DataLoader(icl_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "iwlloader = MultiTaskSamplingLoader(iwldataconfig, dataset=Dataset)\n",
    "iwl_seq_generator = iwlloader.get_seq\n",
    "iwl_dataset = IterDataset(iwl_seq_generator)\n",
    "iwl_dataloader = torch.utils.data.DataLoader(iwl_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "icl2loader = MultiTaskSamplingLoader(icl2dataconfig, dataset=Dataset)\n",
    "icl2_seq_generator = icl2loader.get_seq\n",
    "icl2_dataset = IterDataset(icl2_seq_generator)\n",
    "icl2_dataloader = torch.utils.data.DataLoader(icl2_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "print(\"Train\")\n",
    "cnt = 0\n",
    "for data in train_dataloader:\n",
    "    # print(data.shape)\n",
    "    task = data[\"tasks\"]\n",
    "    examples = data[\"examples\"]\n",
    "    labels = data[\"labels\"]\n",
    "    classes = data[\"classes\"]\n",
    "    # print(examples)\n",
    "    print(\"task\\n\", task)\n",
    "    print(\"train_class\\n\", classes)\n",
    "    print(\"train_label\\n\", labels)\n",
    "    cnt += 1\n",
    "    if cnt > 0:\n",
    "        break\n",
    "print(\"ICL\")\n",
    "cnt = 0\n",
    "for data in icl_dataloader:\n",
    "    task = data[\"tasks\"]\n",
    "    examples = data[\"examples\"]\n",
    "    labels = data[\"labels\"]\n",
    "    classes = data[\"classes\"]\n",
    "    # print(examples)\n",
    "    print(\"task\\n\", task)\n",
    "    print(\"train_class\\n\", classes)\n",
    "    print(\"train_label\\n\", labels)\n",
    "    cnt += 1\n",
    "    if cnt > 0:\n",
    "        break\n",
    "print(\"IWL\")\n",
    "cnt = 0\n",
    "for data in iwl_dataloader:\n",
    "    task = data[\"tasks\"]\n",
    "    examples = data[\"examples\"]\n",
    "    labels = data[\"labels\"]\n",
    "    classes = data[\"classes\"]\n",
    "    print(\"example\",examples.shape)\n",
    "    print(\"task\\n\", task)\n",
    "    print(\"train_class\\n\", classes)\n",
    "    print(\"train_label\\n\", labels)\n",
    "    cnt += 1\n",
    "    if cnt > 0:\n",
    "        break\n",
    "# print(\"ICL2\")\n",
    "# cnt = 0\n",
    "# for data in icl2_dataloader:\n",
    "#     task = data[\"task\"]\n",
    "#     examples = data[\"examples\"]\n",
    "#     labels = data[\"labels\"]\n",
    "#     classes = data[\"classes\"]\n",
    "#     # print(examples)\n",
    "#     print(\"task\", task)\n",
    "#     print(\"train_class\", classes)\n",
    "#     print(\"train_label\", labels)\n",
    "#     cnt += 1\n",
    "#     if cnt > 0:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "\n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, d_vocab, d_model):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(d_vocab, d_model) / np.sqrt(d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.einsum(\"pe,bse->bsp\", self.W, x)\n",
    "\n",
    "\n",
    "class HookPoint(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fwd_hooks = []\n",
    "        self.bwd_hooks = []\n",
    "\n",
    "    def give_name(self, name):\n",
    "        # Called by the model at initialisation\n",
    "        self.name = name\n",
    "\n",
    "    def add_hook(self, hook, dir=\"fwd\"):\n",
    "        # Hook format is fn(activation, hook_name)\n",
    "        # Change it into PyTorch hook format (this includes input and output,\n",
    "        # which are the same for a HookPoint)\n",
    "        def full_hook(module, module_input, module_output):\n",
    "            return hook(module_output, name=self.name)\n",
    "\n",
    "        if dir == \"fwd\":\n",
    "            handle = self.register_forward_hook(full_hook)\n",
    "            self.fwd_hooks.append(handle)\n",
    "        elif dir == \"bwd\":\n",
    "            handle = self.register_backward_hook(full_hook)\n",
    "            self.bwd_hooks.append(handle)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "\n",
    "    def remove_hooks(self, dir=\"fwd\"):\n",
    "        if (dir == \"fwd\") or (dir == \"both\"):\n",
    "            for hook in self.fwd_hooks:\n",
    "                hook.remove()\n",
    "            self.fwd_hooks = []\n",
    "        if (dir == \"bwd\") or (dir == \"both\"):\n",
    "            for hook in self.bwd_hooks:\n",
    "                hook.remove()\n",
    "            self.bwd_hooks = []\n",
    "        if dir not in [\"fwd\", \"bwd\", \"both\"]:\n",
    "            raise ValueError(f\"Invalid direction {dir}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, max_ctx, d_model, weight_scale=1):\n",
    "        super().__init__()\n",
    "        self.W_pos = nn.Parameter(torch.randn(max_ctx, d_model) * weight_scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.W_pos[: x.shape[-2]]\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, epsilon=1e-4, model=[None]):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.w_ln = nn.Parameter(torch.ones(d_model))\n",
    "        self.b_ln = nn.Parameter(torch.zeros(d_model))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.model[0].use_ln:\n",
    "            x = x - x.mean(axis=-1)[..., None]\n",
    "            x = x / (x.std(axis=-1)[..., None] + self.epsilon)\n",
    "            x = x * self.w_ln\n",
    "            x = x + self.b_ln\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "# Attention\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    b : batch size\n",
    "    d : embedding size of token\n",
    "    p : vocabraly size (113 or 3)\n",
    "    i : number of heads\n",
    "    h : embedding size of each heads\n",
    "    n_ctx : token size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, d_head, n_ctx):\n",
    "        super().__init__()\n",
    "        self.W_K = nn.Parameter(\n",
    "            torch.randn(num_heads, d_head, d_model) / np.sqrt(d_model)\n",
    "        )\n",
    "        self.W_Q = nn.Parameter(\n",
    "            torch.randn(num_heads, d_head, d_model) / np.sqrt(d_model)\n",
    "        )\n",
    "        self.W_V = nn.Parameter(\n",
    "            torch.randn(num_heads, d_head, d_model) / np.sqrt(d_model)\n",
    "        )\n",
    "        self.W_O = nn.Parameter(\n",
    "            torch.randn(d_model, d_head * num_heads) / np.sqrt(d_model)\n",
    "        )\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones((n_ctx, n_ctx))))\n",
    "        self.d_head = d_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.W_K.shape, x.shape)\n",
    "        print(self.W_K.device, x.device)\n",
    "        # torch.Size([1, 128, 128]) torch.Size([3, 18, 128])\n",
    "        # cuda:1 cuda:1\n",
    "        k = torch.einsum(\"ihd,bpd->biph\", self.W_K, x)\n",
    "        q = torch.einsum(\"ihd,bpd->biph\", self.W_Q, x)\n",
    "        v = torch.einsum(\"ihd,bpd->biph\", self.W_V, x)\n",
    "        attn_scores_pre = torch.einsum(\"biph,biqh->biqp\", k, q)\n",
    "        attn_scores_masked = torch.tril(attn_scores_pre) - 1e10 * (\n",
    "            1 - self.mask[: x.shape[-2], : x.shape[-2]]\n",
    "        )\n",
    "        attn_matrix = F.softmax(attn_scores_masked / np.sqrt(self.d_head), dim=-1)\n",
    "        z = torch.einsum(\"biph,biqp->biqh\", v, attn_matrix)\n",
    "        z_flat = einops.rearrange(z, \"b i q h -> b q (i h)\")\n",
    "        out = torch.einsum(\"df,bqf->bqd\", self.W_O, z_flat)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, d_in, d_out, act_type, weight_scale=1):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(d_out, d_in))\n",
    "        torch.nn.init.normal_(self.W, mean=0, std=weight_scale / np.sqrt(d_in))\n",
    "\n",
    "    def set_weight_ratio(self, weight_ratio):\n",
    "        self.W = nn.Parameter(self.W * weight_ratio)\n",
    "\n",
    "    def set_weight_ratio_l2(self, weight_ratio):\n",
    "        self.W = nn.Parameter(self.W * torch.sqrt(weight_ratio))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.W.T\n",
    "\n",
    "\n",
    "# for Transformer\n",
    "class MLPBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    b : batch size\n",
    "    d : embedding size of token\n",
    "    p : vocabraly size (114 or 3)\n",
    "    i : number of heads\n",
    "    h : embedding size of each heads\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_mlp, act_type):\n",
    "        super().__init__()\n",
    "        # bias & layer norm are removed.\n",
    "        self.W_in = nn.Parameter(torch.randn(d_mlp, d_model) / np.sqrt(d_model))\n",
    "        self.b_in = nn.Parameter(torch.zeros(d_mlp))\n",
    "        self.W_out = nn.Parameter(torch.randn(d_model, d_mlp) / np.sqrt(d_model))\n",
    "        self.b_out = nn.Parameter(torch.zeros(d_model))\n",
    "        self.act_type = act_type\n",
    "        # self.ln = LayerNorm(d_mlp, model=self.model)\n",
    "        assert act_type in [\"ReLU\", \"GeLU\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.einsum(\"md,bpd->bpm\", self.W_in, x) + self.b_in\n",
    "        if self.act_type == \"ReLU\":\n",
    "            x = F.relu(x)\n",
    "        elif self.act_type == \"GeLU\":\n",
    "            x = F.gelu(x)\n",
    "        x = torch.einsum(\"dm,bpm->bpd\", self.W_out, x) + self.b_out\n",
    "        return x\n",
    "\n",
    "    def set_weight_ratio(self, weight_ratio):\n",
    "        self.W_in = nn.Parameter(self.W_in * weight_ratio)\n",
    "        self.W_out = nn.Parameter(self.W_out * weight_ratio)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    b : batch size\n",
    "    d : embedding size of token\n",
    "    p : vocabraly size\n",
    "    i : number of heads\n",
    "    h : embedding size of each heads\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model):\n",
    "        super().__init__()\n",
    "        # self.ln1 = LayerNorm(d_model, model=self.model)\n",
    "        self.model = model\n",
    "        self.attn = Attention(d_model, num_heads, d_head, n_ctx)\n",
    "        # self.ln2 = LayerNorm(d_model, model=self.model)\n",
    "        self.mlp = MLPBlock(d_model, d_mlp, act_type)\n",
    "        self.layer_norm = LayerNorm(d_model, model=self.model)\n",
    "        self.hook_attn_out = HookPoint()\n",
    "        self.hook_mlp_out = HookPoint()\n",
    "        self.hook_resid_pre = HookPoint()\n",
    "        self.hook_resid_mid = HookPoint()\n",
    "        self.hook_resid_post = HookPoint()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hook_resid_mid(\n",
    "            x + self.hook_attn_out(self.attn((self.hook_resid_pre(x))))\n",
    "        )\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.hook_resid_post(x + self.hook_mlp_out(self.mlp((x))))\n",
    "        return x\n",
    "\n",
    "    def set_weight_ratio(self, weight_ratio):\n",
    "        self.attn.set_weight_ratio(weight_ratio)\n",
    "        self.mlp.set_weight_ratio(weight_ratio)\n",
    "\n",
    "\n",
    "class MultiTaskInputEmbedderV1(nn.Module):\n",
    "    \"\"\"Input embedder.\"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "\n",
    "        \"\"\"Initialize the input embedder.\n",
    "\n",
    "    Args:\n",
    "      num_classes: Total number of output classes.\n",
    "      emb_dim: Dimensionality of example and label embeddings.\n",
    "      example_encoding: How to encode example inputs.\n",
    "        'resnet': simple resnet encoding\n",
    "        'linear': flatten and pass through a linear layer\n",
    "        'embedding': pass through an embedding layer\n",
    "      flatten_superpixels: Whether to flatten the output of the resnet (instead\n",
    "        of taking a mean over superpixels).\n",
    "      example_dropout_prob: Dropout probability on example embeddings. Note that\n",
    "        these are applied at both train and test.\n",
    "      concatenate_labels: Whether to concatenate example and label embeddings\n",
    "        into one token for each (example, label) pair, rather than being fed to\n",
    "        the transformer as two separate tokens.\n",
    "      use_positional_encodings: Whether to use positional encoding.\n",
    "      positional_dropout_prob: Positional dropout probability.\n",
    "      name: Optional name for the module.\n",
    "    \"\"\"\n",
    "        super(MultiTaskInputEmbedderV1, self).__init__()\n",
    "        self._num_classes = conf.d_vocab\n",
    "        self._emb_dim = conf.d_emb\n",
    "        self.p_dim = conf.p_dim\n",
    "        self.num_tasks = conf.num_tasks\n",
    "        self.num_seq_per_task = conf.num_seq_per_task\n",
    "\n",
    "        self.Emb = nn.Linear(self._emb_dim, self._emb_dim)\n",
    "\n",
    "        self.label_embs = nn.Parameter(\n",
    "            torch.randn(self._num_classes, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "        \n",
    "        self.task_embs = nn.Parameter(\n",
    "            torch.randn(self.num_tasks, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, examples, labels, tasks):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            examples (_type_): _description_\n",
    "            labels (_type_): _description_\n",
    "            tasks (_type_): _description_\n",
    "            is_training (bool): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # Encode the example inputs into shape (B, T, SS, E)\n",
    "        B, T, SS, D = examples.shape\n",
    "        examples = examples.view(B, T*SS, D)\n",
    "        # pos encoding\n",
    "        pos_enc = F.one_hot(torch.arange(T*SS), num_classes=self.p_dim).repeat(B,1,1).to(examples.device)\n",
    "        h_example = torch.cat([examples, pos_enc], dim=2) # (B, T*SS, E)\n",
    "        \n",
    "        # Embed the labels. (B, T, SS, 1) -> (B, T*SS, E)\n",
    "        h_label = self.label_embs[labels]  # (B, T, SS, E)\n",
    "        h_label = h_label.view(B, T*SS, self._emb_dim) #(B, T*SS, E)\n",
    "        \n",
    "        # task embedding (B, T) -> (B, T, 1, E)\n",
    "        task_embs = self.task_embs[tasks] # (B, T, E)\n",
    "        \n",
    "        hh = torch.empty(\n",
    "            (B, (SS * 2 +1) * T ,  h_example.shape[2]), # (B, S, E),  S = T*(SS*2 + task) \n",
    "            dtype=h_example.dtype, \n",
    "        ).to(h_example.device)\n",
    "        hh[:, 0::(SS*2+1)] = task_embs\n",
    "        for t in range(T):\n",
    "            hh[:, t*(SS*2+1)+1: t*(SS*2+1)+1 + SS*2:2] = h_example[:, t*SS:(t+1)*SS]\n",
    "            hh[:, t*(SS*2+1)+2:t*(SS*2+1)+1 + SS*2:2] = h_label[:, t*SS:(t+1)*SS]\n",
    "\n",
    "        # last label remove\n",
    "        hh = hh[:, :-1]\n",
    "        \n",
    "\n",
    "        return hh\n",
    "\n",
    "class MultiTaskInputEmbedderV2(nn.Module):\n",
    "    \"\"\"Input embedder.\"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "\n",
    "        \"\"\"Initialize the input embedder.\n",
    "\n",
    "    Args:\n",
    "      num_classes: Total number of output classes.\n",
    "      emb_dim: Dimensionality of example and label embeddings.\n",
    "      example_encoding: How to encode example inputs.\n",
    "        'resnet': simple resnet encoding\n",
    "        'linear': flatten and pass through a linear layer\n",
    "        'embedding': pass through an embedding layer\n",
    "      flatten_superpixels: Whether to flatten the output of the resnet (instead\n",
    "        of taking a mean over superpixels).\n",
    "      example_dropout_prob: Dropout probability on example embeddings. Note that\n",
    "        these are applied at both train and test.\n",
    "      concatenate_labels: Whether to concatenate example and label embeddings\n",
    "        into one token for each (example, label) pair, rather than being fed to\n",
    "        the transformer as two separate tokens.\n",
    "      use_positional_encodings: Whether to use positional encoding.\n",
    "      positional_dropout_prob: Positional dropout probability.\n",
    "      name: Optional name for the module.\n",
    "    \"\"\"\n",
    "        super(MultiTaskInputEmbedderV2, self).__init__()\n",
    "        self._num_classes = conf.d_vocab\n",
    "        self._emb_dim = conf.d_emb\n",
    "        self.p_dim = conf.p_dim\n",
    "        self.num_tasks = conf.num_tasks\n",
    "        self.num_seq_per_task = conf.num_seq_per_task\n",
    "\n",
    "        self.Emb = nn.Linear(self._emb_dim, self._emb_dim)\n",
    "\n",
    "        self.label_embs = nn.Parameter(\n",
    "            torch.randn(self._num_classes, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "        \n",
    "        self.task_embs = nn.Parameter(\n",
    "            torch.randn(self.num_tasks, self._emb_dim) / np.sqrt(self._emb_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, examples, labels, tasks):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            examples (_type_): _description_\n",
    "            labels (_type_): _description_\n",
    "            tasks (_type_): _description_\n",
    "            is_training (bool): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # Encode the example inputs into shape (B, SS, E)\n",
    "        B, SS, D = examples.shape\n",
    "        examples = examples.view(B, SS, D)\n",
    "        # pos encoding\n",
    "        pos_enc = F.one_hot(torch.arange(SS), num_classes=self.p_dim).repeat(B,1,1).to(examples.device)\n",
    "        h_example = torch.cat([examples, pos_enc], dim=2) # (B, SS, E)\n",
    "        \n",
    "        # Embed the labels. (B, SS, 1) -> (B, SS, E)\n",
    "        h_label = self.label_embs[labels]  # (B, SS, E)\n",
    "        h_label = h_label.view(B, SS, self._emb_dim) #(B, SS, E)\n",
    "        \n",
    "        # task embedding (B, SS) -> (B, 1, E)　一つだけ取ってくる\n",
    "        tmp_task = tasks[:, 0]\n",
    "        task_embs = self.task_embs[tmp_task] # (B, 1, E)\n",
    "        hh = torch.empty((B, SS * 2 ,  self._emb_dim), dtype=h_example.dtype, device=h_example.device)\n",
    "        # hh = torch.zeros((B, (SS * 2 ),  h_example.shape[2]), dtype=h_example.dtype, device=h_example.device )\n",
    "        hh[:, 0, :] = task_embs\n",
    "        hh[:, 1::2] = h_example\n",
    "        hh[:, 2::2] = h_label[:, :-1]\n",
    "\n",
    "        # last label remove\n",
    "        # hh = hh[:, :-1]\n",
    "        \n",
    "\n",
    "        return hh\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, embedder, config):\n",
    "        super().__init__()\n",
    "        num_layers = config.num_layers\n",
    "        d_model = config.d_emb\n",
    "        d_mlp = config.d_emb * 4\n",
    "        d_head = config.d_emb // config.num_heads\n",
    "        num_heads = config.num_heads\n",
    "        n_ctx = config.n_ctx\n",
    "        act_type = config.act_type\n",
    "        use_cache = config.use_cache\n",
    "        use_ln = config.use_ln\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "        d_vocab = config.d_vocab\n",
    "\n",
    "        self.embedder = embedder\n",
    "        # self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model=[self]\n",
    "                )\n",
    "                for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        # self.ln = LayerNorm(d_model, model=[self])\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module) == HookPoint:\n",
    "                module.give_name(name)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        x = self.embedder(x, labels,)\n",
    "        # x = self.pos_embed(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if \"hook\" in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks(\"fwd\")\n",
    "            hp.remove_hooks(\"bwd\")\n",
    "\n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name + \"_grad\"] = tensor[0].detach()\n",
    "\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, \"fwd\")\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, \"bwd\")\n",
    "\n",
    "class TransformerICL(nn.Module):\n",
    "    def __init__(self, embedder, config):\n",
    "        super().__init__()\n",
    "        num_layers = config.num_layers\n",
    "        d_model = config.d_emb\n",
    "        d_mlp = config.d_emb * 4\n",
    "        d_head = config.d_emb // config.num_heads\n",
    "        num_heads = config.num_heads\n",
    "        n_ctx = config.n_ctx\n",
    "        act_type = config.act_type\n",
    "        use_cache = config.use_cache\n",
    "        use_ln = config.use_ln\n",
    "        self.cache = {}\n",
    "        self.use_cache = use_cache\n",
    "        d_vocab = config.d_vocab\n",
    "\n",
    "        self.embedder = embedder\n",
    "        # self.pos_embed = PosEmbed(n_ctx, d_model)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Attention(d_model, num_heads, d_head, n_ctx),\n",
    "                Attention(d_model, num_heads, d_head, n_ctx),\n",
    "                Dense(d_model, d_model, act_type),\n",
    "                Dense(d_model, d_model, act_type),\n",
    "                Dense(d_model, d_model, act_type),\n",
    "            ]\n",
    "        )\n",
    "        # self.ln = LayerNorm(d_model, model=[self])\n",
    "        self.unembed = Unembed(d_vocab, d_model)\n",
    "        self.use_ln = use_ln\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if type(module) == HookPoint:\n",
    "                module.give_name(name)\n",
    "\n",
    "    def forward(self, examples, labels, tasks):\n",
    "        x = self.embedder(examples, labels, tasks)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.unembed(x)\n",
    "        return x\n",
    "\n",
    "    def set_use_cache(self, use_cache):\n",
    "        self.use_cache = use_cache\n",
    "\n",
    "    def hook_points(self):\n",
    "        return [module for name, module in self.named_modules() if \"hook\" in name]\n",
    "\n",
    "    def remove_all_hooks(self):\n",
    "        for hp in self.hook_points():\n",
    "            hp.remove_hooks(\"fwd\")\n",
    "            hp.remove_hooks(\"bwd\")\n",
    "\n",
    "    def cache_all(self, cache, incl_bwd=False):\n",
    "        # Caches all activations wrapped in a HookPoint\n",
    "        def save_hook(tensor, name):\n",
    "            cache[name] = tensor.detach()\n",
    "\n",
    "        def save_hook_back(tensor, name):\n",
    "            cache[name + \"_grad\"] = tensor[0].detach()\n",
    "\n",
    "        for hp in self.hook_points():\n",
    "            hp.add_hook(save_hook, \"fwd\")\n",
    "            if incl_bwd:\n",
    "                hp.add_hook(save_hook_back, \"bwd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(t,p):\n",
    "    p_arg = torch.argmax(p,dim=1)\n",
    "    return torch.sum(t == p_arg) / p.shape[0]\n",
    "def to_gpu_dict(dic):\n",
    "    dic = {k:v.to(\"cuda:0\") for k,v in dic.items()}\n",
    "    return dic\n",
    "def to_gpu_dict_list(dic_list):\n",
    "    return np.array([to_gpu_dict(dic) for dic in dic_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "config = MainConfig()\n",
    "wandb.init(project=\"icl-minima-multitask\", config=asdict(config))\n",
    "# data\n",
    "traindataconfig = MainConfig.traindataconfig\n",
    "icldataconfig = MainConfig.icldataconfig\n",
    "iwldataconfig = MainConfig.iwldataconfig\n",
    "icl2dataconfig = MainConfig.icl2dataconfig\n",
    "trainconfig = MainConfig.trainconfig\n",
    "\n",
    "Dataset = SamplingDataset(traindataconfig)\n",
    "\n",
    "trainloader = MultiTaskSamplingLoader(traindataconfig, dataset=Dataset)\n",
    "train_seq_generator = trainloader.get_seq\n",
    "train_dataset = IterDataset(train_seq_generator)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "iclloader = MultiTaskSamplingLoader(icldataconfig, dataset=Dataset)\n",
    "icl_seq_generator = iclloader.get_seq\n",
    "icl_dataset = IterDataset(icl_seq_generator)\n",
    "icl_dataloader = torch.utils.data.DataLoader(icl_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "iwlloader = MultiTaskSamplingLoader(iwldataconfig, dataset=Dataset)\n",
    "iwl_seq_generator = iwlloader.get_seq\n",
    "iwl_dataset = IterDataset(iwl_seq_generator)\n",
    "iwl_dataloader = torch.utils.data.DataLoader(iwl_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "icl2loader = MultiTaskSamplingLoader(icl2dataconfig, dataset=Dataset)\n",
    "icl2_seq_generator = icl2loader.get_seq\n",
    "icl2_dataset = IterDataset(icl2_seq_generator)\n",
    "icl2_dataloader = torch.utils.data.DataLoader(icl2_dataset, batch_size=trainconfig.batch_size, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "# model\n",
    "embedder = MultiTaskInputEmbedderV2(config.modelconfig)\n",
    "model = TransformerICL(embedder, config.modelconfig)\n",
    "model.to(config.device)\n",
    "\n",
    "# optimizer\n",
    "if config.trainconfig.optimizer == \"adam\":\n",
    "  optimizer =  torch.optim.Adam(model.parameters(), lr=config.trainconfig.lr)\n",
    "elif config.trainconfig.optimizer == \"sgd\":\n",
    "  optimizer =  torch.optim.SGD(model.parameters(), lr=config.trainconfig.lr)\n",
    "elif config.trainconfig.optimizer == \"adamw\":\n",
    "  optimizer =  torch.optim.AdamW(model.parameters(), lr=config.trainconfig.lr)\n",
    "\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "step = 0\n",
    "# for (data_dict_list, icl_data_dict_list, iwl_data_dict_list, icl2_data_dict_list) in zip(train_dataloader, icl_dataloader, iwl_dataloader, icl2_dataloader):\n",
    "for data_dict_list in train_dataloader:\n",
    "  model.train()   \n",
    "  data_dict = to_gpu_dict(data_dict_list)\n",
    "  # icl_data_dict = to_gpu_dict(icl_data_dict_list)\n",
    "  # iwl_data_dict = to_gpu_dict(iwl_data_dict_list)\n",
    "  # icl2_data_dict = to_gpu_dict(icl2_data_dict_list)\n",
    "  \n",
    "  # print(\"data_dict\", data_dict)\n",
    "  \n",
    "  logits = model(data_dict[\"examples\"], data_dict[\"labels\"], data_dict[\"tasks\"])\n",
    "  query_logit = logits[:,-1,:]\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  # print(data_dict[\"labels\"][:,-1])\n",
    "  loss = criterion(query_logit, data_dict[\"labels\"][:,-1],)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_acc = cal_acc(data_dict[\"labels\"][:, -1], query_logit)\n",
    "  # print(\"train_sample\", data_dict[\"classes\"], data_dict[\"labels\"])\n",
    "  wandb.log({\"train/acc\":train_acc,\"train/loss\":loss}, step=step)\n",
    "  # with torch.no_grad():\n",
    "  #         model.eval()\n",
    "  #         logits = model(icl_data_dict[\"examples\"], icl_data_dict[\"labels\"], icl_data_dict[\"task\"])\n",
    "  #         query_logit = logits[:,-1,:]\n",
    "  #         icl_acc = cal_acc(icl_data_dict[\"labels\"][:,-1, -1], query_logit)\n",
    "  #         # wandb.log({\"valid/icl_acc\":icl_acc}, step=step)\n",
    "  #         # print(\"\\r\",step, icl_acc, end=\"\")\n",
    "  #         # print(\"icl_sample\", icl_data_dict)\n",
    "\n",
    "  #         logits = model(iwl_data_dict[\"examples\"], iwl_data_dict[\"labels\"], iwl_data_dict[\"task\"])\n",
    "  #         query_logit = logits[:,-1,:]\n",
    "  #         iwl_acc = cal_acc(iwl_data_dict[\"labels\"][:,-1, -1], query_logit)\n",
    "  #         # wandb.log({\"valid/iwl_acc\":iwl_acc}, step=step)\n",
    "  #         # print(\"\\r\",step, iwl_acc, end=\"\")\n",
    "  #         # print(\"iwl_sample\", iwl_data_dict[\"classes\"], iwl_data_dict[\"labels\"])\n",
    "\n",
    "  #         logits = model(icl2_data_dict[\"examples\"], icl2_data_dict[\"labels\"], icl2_data_dict[\"task\"])\n",
    "  #         query_logit = logits[:,-1,:]\n",
    "  #         icl2_acc = cal_acc(icl2_data_dict[\"labels\"][:,-1, -1], query_logit)\n",
    "          # wandb.log({\"valid/icl2_acc\":icl2_acc}, step=step)\n",
    "          # print(\"\\r\",step, icl2_acc, end=\"\")\n",
    "          # print(\"icl2_sample\", icl2_data_dict[\"classes\"], icl2_data_dict[\"labels\"])\n",
    "          \n",
    "  print(\"\\r\",step, train_acc.item())#, iwl_acc.item(), icl_acc.item(), icl2_acc.item(), end=\"\")\n",
    "  step+=1\n",
    "  if step > config.trainconfig.optimize_step:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
